{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3362a434",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default-4177d6418d7b1aec (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to C:\\Users\\19148\\.cache\\huggingface\\datasets\\csv\\default-4177d6418d7b1aec\\0.0.0\\2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2...\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1ab98f9247444259929898832d074c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\19148\\.cache\\huggingface\\datasets\\csv\\default-4177d6418d7b1aec\\0.0.0\\2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19148\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\csv\\2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2\\csv.py:91: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  csv_file_reader = pd.read_csv(\n",
      "C:\\Users\\19148\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\csv\\2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2\\csv.py:91: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  csv_file_reader = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/plain": "(5596, ('求解答这里是讲收敛数列的有界性，为什么举例是这个例子这个数列并不收敛呀这个数列不是发散的吗', 0))"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "#定义数据集\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.dataset = load_dataset(\"csv\",data_dir=\"./\", data_files=\"data_cleaned_5000.csv\", split=split)\n",
    "        # self.dataset = load_dataset(\"csv\",\n",
    "        # data_dir=\"C:/Users/19148/Documents/Pycharm_projects/paper_project\", data_files=\"data_lite.csv\", split=split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        text = self.dataset[i]['text']\n",
    "        label = self.dataset[i]['label']\n",
    "\n",
    "        return text, label\n",
    "\n",
    "\n",
    "dataset = Dataset('train')\n",
    "\n",
    "len(dataset), dataset[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e70a58c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "PreTrainedTokenizer(name_or_path='bert-base-chinese', vocab_size=21128, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "#加载字典和分词工具\n",
    "token = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_len = 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e59695a4",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/349\n",
      "2/349\n",
      "3/349\n",
      "4/349\n",
      "5/349\n",
      "6/349\n",
      "7/349\n",
      "8/349\n",
      "9/349\n",
      "10/349\n",
      "11/349\n",
      "12/349\n",
      "13/349\n",
      "14/349\n",
      "15/349\n",
      "16/349\n",
      "17/349\n",
      "18/349\n",
      "19/349\n",
      "20/349\n",
      "21/349\n",
      "22/349\n",
      "23/349\n",
      "24/349\n",
      "25/349\n",
      "26/349\n",
      "27/349\n",
      "28/349\n",
      "29/349\n",
      "30/349\n",
      "31/349\n",
      "32/349\n",
      "33/349\n",
      "34/349\n",
      "35/349\n",
      "36/349\n",
      "37/349\n",
      "38/349\n",
      "39/349\n",
      "40/349\n",
      "41/349\n",
      "42/349\n",
      "43/349\n",
      "44/349\n",
      "45/349\n",
      "46/349\n",
      "47/349\n",
      "48/349\n",
      "49/349\n",
      "50/349\n",
      "51/349\n",
      "52/349\n",
      "53/349\n",
      "54/349\n",
      "55/349\n",
      "56/349\n",
      "57/349\n",
      "58/349\n",
      "59/349\n",
      "60/349\n",
      "61/349\n",
      "62/349\n",
      "63/349\n",
      "64/349\n",
      "65/349\n",
      "66/349\n",
      "67/349\n",
      "68/349\n",
      "69/349\n",
      "70/349\n",
      "71/349\n",
      "72/349\n",
      "73/349\n",
      "74/349\n",
      "75/349\n",
      "76/349\n",
      "77/349\n",
      "78/349\n",
      "79/349\n",
      "80/349\n",
      "81/349\n",
      "82/349\n",
      "83/349\n",
      "84/349\n",
      "85/349\n",
      "86/349\n",
      "87/349\n",
      "88/349\n",
      "89/349\n",
      "90/349\n",
      "91/349\n",
      "92/349\n",
      "93/349\n",
      "94/349\n",
      "95/349\n",
      "96/349\n",
      "97/349\n",
      "98/349\n",
      "99/349\n",
      "100/349\n",
      "101/349\n",
      "102/349\n",
      "103/349\n",
      "104/349\n",
      "105/349\n",
      "106/349\n",
      "107/349\n",
      "108/349\n",
      "109/349\n",
      "110/349\n",
      "111/349\n",
      "112/349\n",
      "113/349\n",
      "114/349\n",
      "115/349\n",
      "116/349\n",
      "117/349\n",
      "118/349\n",
      "119/349\n",
      "120/349\n",
      "121/349\n",
      "122/349\n",
      "123/349\n",
      "124/349\n",
      "125/349\n",
      "126/349\n",
      "127/349\n",
      "128/349\n",
      "129/349\n",
      "130/349\n",
      "131/349\n",
      "132/349\n",
      "133/349\n",
      "134/349\n",
      "135/349\n",
      "136/349\n",
      "137/349\n",
      "138/349\n",
      "139/349\n",
      "140/349\n",
      "141/349\n",
      "142/349\n",
      "143/349\n",
      "144/349\n",
      "145/349\n",
      "146/349\n",
      "147/349\n",
      "148/349\n",
      "149/349\n",
      "150/349\n",
      "151/349\n",
      "152/349\n",
      "153/349\n",
      "154/349\n",
      "155/349\n",
      "156/349\n",
      "157/349\n",
      "158/349\n",
      "159/349\n",
      "160/349\n",
      "161/349\n",
      "162/349\n",
      "163/349\n",
      "164/349\n",
      "165/349\n",
      "166/349\n",
      "167/349\n",
      "168/349\n",
      "169/349\n",
      "170/349\n",
      "171/349\n",
      "172/349\n",
      "173/349\n",
      "174/349\n",
      "175/349\n",
      "176/349\n",
      "177/349\n",
      "178/349\n",
      "179/349\n",
      "180/349\n",
      "181/349\n",
      "182/349\n",
      "183/349\n",
      "184/349\n",
      "185/349\n",
      "186/349\n",
      "187/349\n",
      "188/349\n",
      "189/349\n",
      "190/349\n",
      "191/349\n",
      "192/349\n",
      "193/349\n",
      "194/349\n",
      "195/349\n",
      "196/349\n",
      "197/349\n",
      "198/349\n",
      "199/349\n",
      "200/349\n",
      "201/349\n",
      "202/349\n",
      "203/349\n",
      "204/349\n",
      "205/349\n",
      "206/349\n",
      "207/349\n",
      "208/349\n",
      "209/349\n",
      "210/349\n",
      "211/349\n",
      "212/349\n",
      "213/349\n",
      "214/349\n",
      "215/349\n",
      "216/349\n",
      "217/349\n",
      "218/349\n",
      "219/349\n",
      "220/349\n",
      "221/349\n",
      "222/349\n",
      "223/349\n",
      "224/349\n",
      "225/349\n",
      "226/349\n",
      "227/349\n",
      "228/349\n",
      "229/349\n",
      "230/349\n",
      "231/349\n",
      "232/349\n",
      "233/349\n",
      "234/349\n",
      "235/349\n",
      "236/349\n",
      "237/349\n",
      "238/349\n",
      "239/349\n",
      "240/349\n",
      "241/349\n",
      "242/349\n",
      "243/349\n",
      "244/349\n",
      "245/349\n",
      "246/349\n",
      "247/349\n",
      "248/349\n",
      "249/349\n",
      "250/349\n",
      "251/349\n",
      "252/349\n",
      "253/349\n",
      "254/349\n",
      "255/349\n",
      "256/349\n",
      "257/349\n",
      "258/349\n",
      "259/349\n",
      "260/349\n",
      "261/349\n",
      "262/349\n",
      "263/349\n",
      "264/349\n",
      "265/349\n",
      "266/349\n",
      "267/349\n",
      "268/349\n",
      "269/349\n",
      "270/349\n",
      "271/349\n",
      "272/349\n",
      "273/349\n",
      "274/349\n",
      "275/349\n",
      "276/349\n",
      "277/349\n",
      "278/349\n",
      "279/349\n",
      "280/349\n",
      "281/349\n",
      "282/349\n",
      "283/349\n",
      "284/349\n",
      "285/349\n",
      "286/349\n",
      "287/349\n",
      "288/349\n",
      "289/349\n",
      "290/349\n",
      "291/349\n",
      "292/349\n",
      "293/349\n",
      "294/349\n",
      "295/349\n",
      "296/349\n",
      "297/349\n",
      "298/349\n",
      "299/349\n",
      "300/349\n",
      "301/349\n",
      "302/349\n",
      "303/349\n",
      "304/349\n",
      "305/349\n",
      "306/349\n",
      "307/349\n",
      "308/349\n",
      "309/349\n",
      "310/349\n",
      "311/349\n",
      "312/349\n",
      "313/349\n",
      "314/349\n",
      "315/349\n",
      "316/349\n",
      "317/349\n",
      "318/349\n",
      "319/349\n",
      "320/349\n",
      "321/349\n",
      "322/349\n",
      "323/349\n",
      "324/349\n",
      "325/349\n",
      "326/349\n",
      "327/349\n",
      "328/349\n",
      "329/349\n",
      "330/349\n",
      "331/349\n",
      "332/349\n",
      "333/349\n",
      "334/349\n",
      "335/349\n",
      "336/349\n",
      "337/349\n",
      "338/349\n",
      "339/349\n",
      "340/349\n",
      "341/349\n",
      "342/349\n",
      "343/349\n",
      "344/349\n",
      "345/349\n",
      "346/349\n",
      "347/349\n",
      "348/349\n",
      "349/349\n",
      "349\n"
     ]
    },
    {
     "data": {
      "text/plain": "(torch.Size([16, 300]),\n torch.Size([16, 300]),\n torch.Size([16, 300]),\n tensor([3, 1, 0, 3, 0, 3, 1, 1, 3, 2, 0, 1, 0, 2, 1, 0]))"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(data):\n",
    "    sents = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "\n",
    "    #编码\n",
    "    data = token.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=max_len,\n",
    "                                   return_tensors='pt',\n",
    "                                   return_length=True)\n",
    "\n",
    "    #input_ids:编码之后的数字\n",
    "    #attention_mask:是补零的位置是0,其他位置是1\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = data['attention_mask']\n",
    "    token_type_ids = data['token_type_ids']\n",
    "    labels = torch.LongTensor(labels)\n",
    "\n",
    "    #print(data['length'], data['length'].max())\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, labels\n",
    "\n",
    "\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     # shuffle=False,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "len_loader = len(loader)\n",
    "for i, (input_ids, attention_mask, token_type_ids,\n",
    "        labels) in enumerate(loader):\n",
    "    print(\"%d/%d\"%(i+1,len_loader))\n",
    "    # print(labels)\n",
    "    # print(input_ids.shape)\n",
    "    # break\n",
    "\n",
    "print(len(loader))\n",
    "input_ids.shape, attention_mask.shape, token_type_ids.shape, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f620d0e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 300, 768])\n",
      "1/349 2/349 3/349 4/349 5/349 6/349 7/349 8/349 \n",
      "9/349 10/349 11/349 12/349 13/349 14/349 15/349 16/349 \n",
      "17/349 18/349 19/349 20/349 21/349 22/349 23/349 24/349 \n",
      "25/349 26/349 27/349 28/349 29/349 30/349 31/349 32/349 \n",
      "33/349 34/349 35/349 36/349 37/349 38/349 39/349 40/349 \n",
      "41/349 42/349 43/349 44/349 45/349 46/349 47/349 48/349 \n",
      "49/349 50/349 51/349 52/349 53/349 54/349 55/349 56/349 \n",
      "57/349 58/349 59/349 60/349 61/349 62/349 63/349 64/349 \n",
      "65/349 66/349 67/349 68/349 69/349 70/349 71/349 72/349 \n",
      "73/349 74/349 75/349 76/349 77/349 78/349 79/349 80/349 \n",
      "81/349 82/349 83/349 84/349 85/349 86/349 87/349 88/349 \n",
      "89/349 90/349 91/349 92/349 93/349 94/349 95/349 96/349 \n",
      "97/349 98/349 99/349 100/349 101/349 102/349 103/349 104/349 \n",
      "105/349 106/349 107/349 108/349 109/349 110/349 111/349 112/349 \n",
      "113/349 114/349 115/349 116/349 117/349 118/349 119/349 120/349 \n",
      "121/349 122/349 123/349 124/349 125/349 126/349 127/349 128/349 \n",
      "129/349 130/349 131/349 132/349 133/349 134/349 135/349 136/349 \n",
      "137/349 138/349 139/349 140/349 141/349 142/349 143/349 144/349 \n",
      "145/349 146/349 147/349 148/349 149/349 150/349 151/349 152/349 \n",
      "153/349 154/349 155/349 156/349 157/349 158/349 159/349 160/349 \n",
      "161/349 162/349 163/349 164/349 165/349 166/349 167/349 168/349 \n",
      "169/349 170/349 171/349 172/349 173/349 174/349 175/349 176/349 \n",
      "177/349 178/349 179/349 180/349 181/349 182/349 183/349 184/349 \n",
      "185/349 186/349 187/349 188/349 189/349 190/349 191/349 192/349 \n",
      "193/349 194/349 195/349 196/349 197/349 198/349 199/349 200/349 \n",
      "201/349 202/349 203/349 204/349 205/349 206/349 207/349 208/349 \n",
      "209/349 210/349 211/349 212/349 213/349 214/349 215/349 216/349 \n",
      "217/349 218/349 219/349 220/349 221/349 222/349 223/349 224/349 \n",
      "225/349 226/349 227/349 228/349 229/349 230/349 231/349 232/349 \n",
      "233/349 234/349 235/349 236/349 237/349 238/349 239/349 240/349 \n",
      "241/349 242/349 243/349 244/349 245/349 246/349 247/349 248/349 \n",
      "249/349 250/349 251/349 252/349 253/349 254/349 255/349 256/349 \n",
      "257/349 258/349 259/349 260/349 261/349 262/349 263/349 264/349 \n",
      "265/349 266/349 267/349 268/349 269/349 270/349 271/349 272/349 \n",
      "273/349 274/349 275/349 276/349 277/349 278/349 279/349 280/349 \n",
      "281/349 282/349 283/349 284/349 285/349 286/349 287/349 288/349 \n",
      "289/349 290/349 291/349 292/349 293/349 294/349 295/349 296/349 \n",
      "297/349 298/349 299/349 300/349 301/349 302/349 303/349 304/349 \n",
      "305/349 306/349 307/349 308/349 309/349 310/349 311/349 312/349 \n",
      "313/349 314/349 315/349 316/349 317/349 318/349 319/349 320/349 \n",
      "321/349 322/349 323/349 324/349 325/349 326/349 327/349 328/349 \n",
      "329/349 330/349 331/349 332/349 333/349 334/349 335/349 336/349 \n",
      "337/349 338/349 339/349 340/349 341/349 342/349 343/349 344/349 \n",
      "345/349 346/349 347/349 348/349 349/349 torch.Size([5596, 768]) torch.Size([5596])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "#加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-chinese')\n",
    "\n",
    "#不训练,不需要计算梯度\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "#模型试算\n",
    "out = pretrained(input_ids=input_ids,\n",
    "           attention_mask=attention_mask,\n",
    "           token_type_ids=token_type_ids)\n",
    "\n",
    "print(out.last_hidden_state.shape)\n",
    "# print(out.last_hidden_state[1,0])\n",
    "w2v = torch.zeros(len(dataset), 768)\n",
    "label = torch.zeros(len(dataset))\n",
    "len_loader = len(loader)\n",
    "for i, (input_ids, attention_mask, token_type_ids,\n",
    "        labels) in enumerate(loader): # 这样就行了\n",
    "    print(\"%d/%d\"%(i+1,len_loader),end=' ')\n",
    "    if i%8 == 7:\n",
    "        print('\\n', end='')\n",
    "    out = pretrained(input_ids=input_ids,\n",
    "           attention_mask=attention_mask,\n",
    "           token_type_ids=token_type_ids)\n",
    "    vec = out.last_hidden_state\n",
    "    for j in range(batch_size):  # batch_size=16\n",
    "        w2v[batch_size * i + j] = torch.mean(vec[j], dim=0, keepdim=True)  # 取均值，而不是第一个值\n",
    "        # w2v[batch_size * i + j] = vec[j,0]  # vector\n",
    "        label[batch_size * i + j] = labels[j]\n",
    "print(w2v.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "w2v_list = w2v.tolist()\n",
    "# l_list = label.tolist()\n",
    "total = np.concatenate((w2v_list, label.reshape(len(label), 1)), axis=1)\n",
    "tp = pd.DataFrame(total)\n",
    "# tp.to_csv(\"w2v.csv\", header=None, index=None)\n",
    "tp.to_csv(\"w2v_cleaned_mean_shuffle_5000.csv\", header=None, index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/229 2/229 3/229 4/229 5/229 6/229 7/229 8/229 \n",
      "9/229 10/229 11/229 12/229 13/229 14/229 15/229 16/229 \n",
      "17/229 18/229 19/229 20/229 21/229 22/229 23/229 24/229 \n",
      "25/229 26/229 27/229 28/229 29/229 30/229 31/229 32/229 \n",
      "33/229 34/229 35/229 36/229 37/229 38/229 39/229 40/229 \n",
      "41/229 42/229 43/229 44/229 45/229 46/229 47/229 48/229 \n",
      "49/229 50/229 51/229 52/229 53/229 54/229 55/229 56/229 \n",
      "57/229 58/229 59/229 60/229 61/229 62/229 63/229 64/229 \n",
      "65/229 66/229 67/229 68/229 69/229 70/229 71/229 72/229 \n",
      "73/229 74/229 75/229 76/229 77/229 78/229 79/229 80/229 \n",
      "81/229 82/229 83/229 84/229 85/229 86/229 87/229 88/229 \n",
      "89/229 90/229 91/229 92/229 93/229 94/229 95/229 96/229 \n",
      "97/229 98/229 99/229 100/229 101/229 102/229 103/229 104/229 \n",
      "105/229 106/229 107/229 108/229 109/229 110/229 111/229 112/229 \n",
      "113/229 114/229 115/229 116/229 117/229 118/229 119/229 120/229 \n",
      "121/229 122/229 123/229 124/229 125/229 126/229 127/229 128/229 \n",
      "129/229 130/229 131/229 132/229 133/229 134/229 135/229 136/229 \n",
      "137/229 138/229 139/229 140/229 141/229 142/229 143/229 144/229 \n",
      "145/229 146/229 147/229 148/229 149/229 150/229 151/229 152/229 \n",
      "153/229 154/229 155/229 156/229 157/229 158/229 159/229 160/229 \n",
      "161/229 162/229 163/229 164/229 165/229 166/229 167/229 168/229 \n",
      "169/229 170/229 171/229 172/229 173/229 174/229 175/229 176/229 \n",
      "177/229 178/229 179/229 180/229 181/229 182/229 183/229 184/229 \n",
      "185/229 186/229 187/229 188/229 189/229 190/229 191/229 192/229 \n",
      "193/229 194/229 195/229 196/229 197/229 198/229 199/229 200/229 \n",
      "201/229 202/229 203/229 204/229 205/229 206/229 207/229 208/229 \n",
      "209/229 210/229 211/229 212/229 213/229 214/229 215/229 216/229 \n",
      "217/229 218/229 219/229 220/229 221/229 222/229 223/229 224/229 \n",
      "225/229 226/229 227/229 228/229 229/229 torch.Size([3664, 300])\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(768, 300)\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        with torch.no_grad():\n",
    "            out = pretrained(input_ids=input_ids,\n",
    "                       attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids)\n",
    "        out = self.fc(out.last_hidden_state)\n",
    "        # out = out.softmax(dim=1)\n",
    "        return out\n",
    "model = Model()\n",
    "w2v_low_dim = torch.zeros(len(dataset), 300)\n",
    "for i, (input_ids, attention_mask, token_type_ids,\n",
    "        labels) in enumerate(loader): # 这样就行了\n",
    "    print(\"%d/%d\"%(i+1,len_loader),end=' ')\n",
    "    if i%8 == 7:\n",
    "        print('\\n', end='')\n",
    "    out = model(input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "    for j in range(batch_size):  # batch_size=16\n",
    "        # w2v_low_dim[batch_size * i + j] = out[j,0]  # vector\n",
    "        # 取均值，而不是第一个值\n",
    "        w2v_low_dim[batch_size * i + j] = torch.mean(out[j], dim=0, keepdim=True)\n",
    "print(w2v_low_dim.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3664, 300])\n",
      "torch.Size([3664, 300])\n"
     ]
    }
   ],
   "source": [
    "print(w2v_low_dim.shape)\n",
    "fc = torch.nn.Linear(768, 300)\n",
    "temp = fc(w2v)\n",
    "print(temp.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "w2v_low_dim_list = w2v_low_dim.tolist()\n",
    "# w2v_low_dim_list = temp.tolist()\n",
    "total_low_dim = np.concatenate((w2v_low_dim_list, label.reshape(len(label), 1)), axis=1)\n",
    "tq = pd.DataFrame(total_low_dim)\n",
    "# tp.to_csv(\"w2v.csv\", header=None, index=None)\n",
    "tq.to_csv(\"w2v_big_low_dim_mean.csv\", header=None, index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d3d02a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#定义下游任务模型\n",
    "# class Model(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         # self.fc = torch.nn.Linear(768, 2)\n",
    "#\n",
    "#     def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "#         with torch.no_grad():\n",
    "#             out = pretrained(input_ids=input_ids,\n",
    "#                        attention_mask=attention_mask,\n",
    "#                        token_type_ids=token_type_ids)\n",
    "#\n",
    "#         out = self.fc(out.last_hidden_state)\n",
    "#\n",
    "#         # out = out.softmax(dim=1)\n",
    "#\n",
    "#         return out\n",
    "#\n",
    "#\n",
    "# model = Model()\n",
    "#\n",
    "# out = model(input_ids=input_ids,\n",
    "#       attention_mask=attention_mask,\n",
    "#       token_type_ids=token_type_ids)\n",
    "# print(out)\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd44a7c",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6782209873199463 0.625\n",
      "5 0.5840441584587097 0.75\n",
      "10 0.6991336941719055 0.375\n",
      "15 0.6459898948669434 0.625\n",
      "20 0.6601291298866272 0.5625\n",
      "25 0.6269813776016235 0.8125\n",
      "30 0.595515251159668 0.875\n",
      "35 0.5542500019073486 0.875\n",
      "40 0.5360901355743408 0.8125\n",
      "45 0.5258952379226685 0.9375\n",
      "50 0.5396168828010559 0.875\n",
      "55 0.5625669956207275 0.75\n",
      "60 0.503290057182312 0.875\n",
      "65 0.5144746899604797 0.75\n",
      "70 0.4966588318347931 0.875\n",
      "75 0.5100283622741699 0.8125\n",
      "80 0.5462980270385742 0.6875\n",
      "85 0.5015004873275757 0.9375\n",
      "90 0.4921759068965912 0.875\n",
      "95 0.5301690697669983 0.8125\n",
      "100 0.4322471618652344 0.9375\n",
      "105 0.4398854672908783 1.0\n",
      "110 0.6205551028251648 0.6875\n",
      "115 0.4555570185184479 0.9375\n",
      "120 0.43458104133605957 0.9375\n",
      "125 0.5856747031211853 0.8125\n",
      "130 0.45579853653907776 0.875\n",
      "135 0.49450209736824036 0.875\n",
      "140 0.4834059476852417 0.875\n",
      "145 0.41298091411590576 0.9375\n",
      "150 0.6239964365959167 0.6875\n",
      "155 0.42134153842926025 0.9375\n",
      "160 0.41760149598121643 1.0\n",
      "165 0.4275535047054291 0.9375\n",
      "170 0.5800575613975525 0.75\n",
      "175 0.44518887996673584 0.875\n",
      "180 0.42843857407569885 0.9375\n",
      "185 0.4298834800720215 0.9375\n",
      "190 0.46833470463752747 0.8125\n",
      "195 0.48308607935905457 0.8125\n",
      "200 0.5299521684646606 0.8125\n",
      "205 0.41276633739471436 0.9375\n",
      "210 0.4676920771598816 0.875\n",
      "215 0.4392228424549103 0.875\n",
      "220 0.4800220727920532 0.875\n",
      "225 0.5499932169914246 0.6875\n",
      "230 0.4250292479991913 0.875\n",
      "235 0.44226840138435364 0.9375\n",
      "240 0.527982771396637 0.75\n",
      "245 0.398252934217453 0.9375\n",
      "250 0.4963655173778534 0.875\n",
      "255 0.5123838186264038 0.8125\n",
      "260 0.4301964342594147 0.9375\n",
      "265 0.561985969543457 0.8125\n",
      "270 0.5266203880310059 0.75\n",
      "275 0.4799845516681671 0.8125\n",
      "280 0.3876492977142334 0.9375\n",
      "285 0.4564688503742218 0.8125\n",
      "290 0.4763532280921936 0.875\n",
      "295 0.538104772567749 0.75\n",
      "300 0.39595580101013184 0.9375\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "#训练\n",
    "# optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# model.train()\n",
    "for i, (input_ids, attention_mask, token_type_ids,\n",
    "        labels) in enumerate(loader): # 这样就行了\n",
    "    out = model(input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "\n",
    "    loss = criterion(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        out = out.argmax(dim=1)\n",
    "        accuracy = (out == labels).sum().item() / len(labels)\n",
    "\n",
    "        print(i, loss.item(), accuracy)\n",
    "\n",
    "    if i == 300:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "275dd1b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset chn_senti_corp (/Users/lee/.cache/huggingface/datasets/seamew___chn_senti_corp/default/0.0.0/1f242195a37831906957a11a2985a4329167e60657c07dc95ebe266c03fdfb85)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0.86875\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=Dataset('validation'),\n",
    "                                              batch_size=32,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "\n",
    "    for i, (input_ids, attention_mask, token_type_ids,\n",
    "            labels) in enumerate(loader_test):\n",
    "\n",
    "        if i == 5:\n",
    "            break\n",
    "\n",
    "        print(i)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "\n",
    "        out = out.argmax(dim=1)\n",
    "        correct += (out == labels).sum().item()\n",
    "        total += len(labels)\n",
    "\n",
    "    print(correct / total)\n",
    "\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}