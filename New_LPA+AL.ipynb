{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) 5596\n",
      "train_indices 5196 [2180 5577  111 ... 1667 3321 1688]\n",
      "test_indices 400 [3064 4688 4763 4648  893 4782 2082 4329 3033 4183 2165 4615 3579 3465\n",
      " 4979 1793 4817 3528 4975  349 1989 4885 3406   21 2326  836 3706 3952\n",
      " 2375  933 1182 2494 1352 3887 3491 4788  808 3455 2674 4787 1746 4297\n",
      " 2315 5407 2019 4934 4614  779  279 4233  617 3914 4751 4089   17 5406\n",
      " 3815 5191  884   94  350 4412 1053 2369  454 4080 5287 3229 4864 1964\n",
      " 2818 3296 3172 3145 4178 3702 3937 1361 2897 3805 4133 3723 4018 2719\n",
      " 1176 5411 1370 1094 1743 4261 3561 4264 1458 3677 4993 4126 4118  602\n",
      " 4084 5144  569 1891  640 5188 2055 4064  666  531  862 4857  451 1166\n",
      "   33 3171 3865 1203 4870 5516 1577  261  281 2475 4044 3592 3066 3021\n",
      " 5319 5017 2872 1801 5296 2495 1757 4766 1617  158 2696  955 1822 4899\n",
      " 3549 1300 3313 5110 1260 3113 2260 3503 1879  205  762 5002 4121 3829\n",
      " 1624   23 2559   24    9   87 4732 2465 2378 4212 4225 3248 5129 4525\n",
      " 2022 3095 2882 3716 5488 2802 1655 1117 4170 1876  626  899 5010 4454\n",
      " 4628 2408 3514 3604 3519 5281 3893 5123 5424 3908 4947 1733 5175 2462\n",
      " 1679 4061  994 1680 1928 1030  346 2500 4077 1044 4918 5512 1977 4408\n",
      " 1140 4910 2884 2292 2891  467 1866 3352 4475 4168 4187 5083 3159  445\n",
      "  368  273 2463 4478 1947   57  433 1496 3252 4242 4650 2434 2959 2985\n",
      "  371 5402 1890 4122  534 1585 1364 3341  809 3817 4500 3136  367 2586\n",
      " 4181 4859 1476 3357  521 4643 5266 5332 4686 2181  330 3638 3878 2152\n",
      " 2459 3160 1229 5171 1736 1173 1842 1452 2770 2285  500 4338 4912 1046\n",
      " 4941 2041 2816 3063 3237 4943 2119 1103  832 1333  465  236 3029 3830\n",
      " 4490  203 2819 4072 2883  905  800 4832  206  686 1567 1686 4255  920\n",
      " 3965 1238 1499 4119  213 3260 3166 3250 3973 4331 2314 2380 4068 3338\n",
      " 1983 5545 1139 2493 2103 3713 1295 1723  696  915 5330 2086  232 1188\n",
      "  590 3573 3584 3562 4728 1444 1087 1530 3032 5011 2543 5511 4880  738\n",
      " 4837 3894 3468 3510 4861 4508  796 3452 4964 5486 4647 1057  967 1872\n",
      " 5333  331  743 1051   20 4249 3456 2786 1998  641 1871 5380 3301 4800\n",
      " 1425 2864 3497 5077 1698 1409  550 5502 2841 2659 2731  997 2445 3833\n",
      " 2223  981   92 4694 4684 3775  241 4340]\n",
      "[0.14852939 0.1030991  0.11490163 ... 0.25518958 0.17510298 0.19572474] 5196\n",
      "[1032 1814 3352 ... 3311 2276 1880] 5196\n",
      "[1032 1814 4730 ... 3325 3071 1056] 1600\n",
      "len(new_x) 2000\n",
      "len(new_y) 2000\n",
      "predicted_labels [0. 3. 2. 1. 2. 3. 0. 2. 2. 0. 1. 0. 1. 0. 0. 2. 0. 2. 3. 0. 1. 0. 0. 3.\n",
      " 1. 3. 0. 2. 0. 0. 2. 0. 3. 2. 2. 3. 3. 0. 2. 2. 0. 2. 3. 2. 2. 0. 1. 0.\n",
      " 2. 2. 2. 1. 2. 0. 1. 2. 1. 3. 0. 1. 0. 2. 0. 0. 3. 1. 0. 0. 3. 0. 1. 2.\n",
      " 0. 0. 3. 2. 0. 0. 2. 0. 0. 3. 2. 1. 0. 0. 2. 1. 1. 0. 2. 2. 0. 0. 2. 1.\n",
      " 0. 2. 1. 2. 2. 2. 2. 0. 3. 0. 0. 0. 1. 3. 2. 1. 0. 0. 0. 0. 1. 0. 2. 2.\n",
      " 1. 0. 0. 0. 0. 2. 1. 2. 2. 2. 1. 0. 1. 0. 1. 3. 2. 2. 1. 2. 0. 0. 0. 0.\n",
      " 2. 3. 0. 1. 1. 2. 0. 3. 0. 1. 0. 2. 0. 2. 3. 2. 0. 3. 1. 1. 2. 3. 3. 0.\n",
      " 3. 1. 0. 3. 1. 1. 3. 0. 1. 3. 2. 1. 2. 0. 0. 1. 0. 3. 2. 1. 3. 2. 0. 1.\n",
      " 2. 3. 2. 1. 2. 3. 3. 2. 3. 1. 1. 0. 2. 0. 2. 2. 1. 2. 1. 1. 1. 2. 1. 1.\n",
      " 2. 2. 1. 3. 0. 0. 1. 0. 3. 0. 2. 0. 3. 0. 2. 0. 2. 3. 2. 3. 3. 1. 3. 0.\n",
      " 0. 0. 0. 0. 3. 3. 3. 0. 1. 1. 1. 0. 0. 1. 1. 3. 0. 0. 3. 0. 0. 3. 3. 2.\n",
      " 0. 0. 3. 3. 2. 1. 0. 0. 1. 0. 2. 2. 0. 1. 2. 1. 3. 0. 2. 1. 0. 2. 3. 0.\n",
      " 1. 2. 2. 1. 0. 2. 3. 1. 2. 0. 3. 0. 1. 2. 2. 2. 0. 1. 0. 2. 1. 0. 3. 2.\n",
      " 1. 3. 1. 0. 3. 1. 0. 2. 1. 0. 2. 2. 2. 2. 2. 2. 3. 0. 1. 1. 1. 2. 0. 1.\n",
      " 0. 1. 2. 2. 0. 2. 1. 0. 0. 0. 3. 1. 1. 3. 1. 1. 1. 2. 0. 3. 0. 3. 0. 1.\n",
      " 0. 3. 0. 2. 0. 2. 2. 1. 3. 2. 0. 3. 0. 2. 3. 0. 2. 3. 2. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 3. 1. 0. 1. 2. 0. 1. 1. 1. 3.]\n",
      "true_labels [1. 2. 2. 1. 2. 3. 0. 0. 2. 0. 1. 2. 1. 3. 1. 2. 0. 2. 3. 0. 1. 0. 0. 3.\n",
      " 1. 3. 0. 2. 0. 0. 2. 0. 3. 3. 2. 3. 2. 0. 1. 0. 0. 3. 2. 2. 2. 0. 1. 0.\n",
      " 3. 2. 2. 1. 3. 0. 1. 2. 1. 3. 0. 1. 0. 1. 0. 0. 3. 2. 0. 0. 3. 0. 1. 2.\n",
      " 0. 0. 3. 2. 1. 0. 0. 0. 0. 3. 0. 0. 0. 0. 1. 1. 1. 0. 2. 0. 0. 0. 1. 1.\n",
      " 0. 2. 2. 3. 3. 2. 2. 0. 3. 0. 2. 0. 1. 2. 2. 1. 0. 0. 0. 1. 1. 0. 3. 2.\n",
      " 1. 0. 0. 1. 0. 2. 1. 2. 2. 2. 1. 0. 1. 0. 1. 3. 2. 2. 1. 2. 0. 0. 0. 0.\n",
      " 2. 3. 1. 1. 1. 2. 0. 3. 0. 1. 0. 2. 0. 2. 2. 2. 0. 3. 1. 1. 2. 2. 3. 0.\n",
      " 3. 1. 1. 3. 1. 1. 0. 0. 0. 3. 2. 1. 2. 0. 0. 1. 0. 3. 2. 1. 3. 1. 0. 3.\n",
      " 2. 1. 2. 1. 2. 3. 3. 2. 3. 1. 1. 0. 2. 0. 2. 2. 1. 2. 1. 1. 1. 3. 2. 1.\n",
      " 3. 1. 1. 2. 0. 0. 1. 0. 3. 0. 2. 0. 3. 0. 3. 0. 2. 3. 1. 3. 3. 1. 3. 0.\n",
      " 1. 2. 0. 0. 2. 3. 3. 0. 1. 1. 1. 0. 0. 1. 1. 3. 0. 0. 1. 0. 0. 3. 3. 2.\n",
      " 0. 0. 3. 2. 0. 1. 0. 0. 1. 0. 1. 2. 0. 2. 2. 1. 3. 0. 0. 0. 0. 2. 2. 0.\n",
      " 1. 2. 2. 1. 2. 2. 3. 1. 2. 0. 3. 0. 1. 0. 2. 2. 0. 1. 0. 2. 0. 0. 2. 2.\n",
      " 1. 3. 1. 0. 2. 1. 0. 3. 1. 0. 2. 2. 2. 2. 2. 3. 3. 0. 1. 1. 1. 2. 0. 1.\n",
      " 2. 1. 2. 2. 0. 2. 1. 0. 0. 0. 3. 1. 1. 3. 1. 1. 1. 0. 0. 3. 0. 3. 0. 1.\n",
      " 1. 3. 0. 2. 3. 2. 0. 1. 3. 3. 0. 2. 0. 2. 3. 0. 3. 3. 2. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 3. 2. 0. 1. 3. 0. 1. 1. 1. 3.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8769    0.8837    0.8803       129\n",
      "         1.0     0.8969    0.8208    0.8571       106\n",
      "         2.0     0.6857    0.7579    0.7200        95\n",
      "         3.0     0.7647    0.7429    0.7536        70\n",
      "\n",
      "    accuracy                         0.8125       400\n",
      "   macro avg     0.8061    0.8013    0.8028       400\n",
      "weighted avg     0.8172    0.8125    0.8139       400\n",
      "\n",
      "Confusion matrix\n",
      "[[114   4  10   1]\n",
      " [  9  87   8   2]\n",
      " [  5   5  72  13]\n",
      " [  2   1  15  52]]\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(open(\"w2v_cleaned_mean_shuffle_5000.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "X = data[:, : -1]  # 输入\n",
    "y = data[:, -1]  # 标签\n",
    "print(\"len(data)\",len(data))\n",
    "rng = np.random.RandomState(3)  # 随机数种子\n",
    "indices = np.arange(len(data))\n",
    "rng.shuffle(indices)  # 将索引打乱\n",
    "train_indices = indices[400:]\n",
    "print(\"train_indices\", len(train_indices), train_indices)\n",
    "test_indices = indices[:400]\n",
    "print(\"test_indices\", len(test_indices), test_indices)\n",
    "\n",
    "\n",
    "lp_model = LabelSpreading(gamma=0.32, max_iter=30)# 下一步循环得到最好结果的gamma\n",
    "lp_model.fit(X[train_indices], y[train_indices])\n",
    "pred_entropies = stats.distributions.entropy(lp_model.label_distributions_.T)\n",
    "print(pred_entropies,len(pred_entropies))\n",
    "# 选择分类器最不确定的最多5位数字示例\n",
    "uncertainty_index = np.argsort(pred_entropies)[::-1]\n",
    "print(uncertainty_index,len(uncertainty_index))\n",
    "uncertainty_index = uncertainty_index[\n",
    "np.in1d(uncertainty_index, train_indices)][:1600]\n",
    "print(uncertainty_index,len(uncertainty_index))\n",
    "\n",
    "as_labeled_indices = uncertainty_index # 挑选出的1600个样本作为传播的起点\n",
    "new_index = np.concatenate((as_labeled_indices, test_indices),axis=0)# 总共的2000样本索引\n",
    "new_x = X[new_index]\n",
    "new_y = y[new_index]\n",
    "new_y[1600:] = -1\n",
    "print(\"len(new_x)\",len(new_x))\n",
    "print(\"len(new_y)\",len(new_y))\n",
    "\n",
    "lp_model.fit(new_x, new_y)\n",
    "predicted_labels = lp_model.transduction_[1600:]\n",
    "print(\"predicted_labels\", predicted_labels)\n",
    "true_labels = y[test_indices]\n",
    "print(\"true_labels\",true_labels)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels,\n",
    "                          labels=lp_model.classes_)\n",
    "\n",
    "print(classification_report(true_labels, predicted_labels, digits=4))\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 0.63\n",
      "1 0.011233240329780276 0.6275\n",
      "2 0.012618568830660204 0.63\n",
      "3 0.014174741629268055 0.63\n",
      "4 0.015922827933410922 0.625\n",
      "5 0.01788649529057435 0.62\n",
      "6 0.02009233002565047 0.62\n",
      "7 0.022570197196339202 0.605\n",
      "8 0.025353644939701114 0.61\n",
      "9 0.02848035868435802 0.6125\n",
      "10 0.03199267137797385 0.6225\n",
      "11 0.03593813663804628 0.6425\n",
      "12 0.040370172585965536 0.65\n",
      "13 0.04534878508128582 0.6625\n",
      "14 0.0509413801481638 0.685\n",
      "15 0.05722367659350217 0.6975\n",
      "16 0.06428073117284319 0.7075\n",
      "17 0.07220809018385464 0.715\n",
      "18 0.08111308307896872 0.735\n",
      "19 0.09111627561154892 0.74\n",
      "20 0.10235310218990264 0.745\n",
      "21 0.11497569953977356 0.76\n",
      "22 0.1291549665014884 0.765\n",
      "23 0.14508287784959395 0.7725\n",
      "24 0.16297508346206444 0.7725\n",
      "25 0.18307382802953678 0.7775\n",
      "26 0.20565123083486514 0.8\n",
      "27 0.23101297000831592 0.795\n",
      "28 0.25950242113997357 0.8075\n",
      "29 0.2915053062825176 0.8025\n",
      "30 0.32745491628777285 0.8075\n",
      "31 0.36783797718286326 0.7975\n",
      "32 0.41320124001153363 0.8025\n",
      "33 0.464158883361278 0.79\n",
      "34 0.5214008287999684 0.7875\n",
      "35 0.5857020818056667 0.785\n",
      "36 0.6579332246575679 0.7825\n",
      "37 0.739072203352578 0.765\n",
      "38 0.8302175681319743 0.7725\n",
      "39 0.9326033468832199 0.7675\n",
      "40 1.0476157527896652 0.7625\n",
      "41 1.1768119524349978 0.76\n",
      "42 1.3219411484660286 0.7575\n",
      "43 1.484968262254465 0.7575\n",
      "44 1.6681005372000592 0.7525\n",
      "45 1.873817422860383 0.75\n",
      "46 2.1049041445120196 0.755\n",
      "47 2.364489412645407 0.755\n",
      "48 2.656087782946687 0.755\n",
      "49 2.9836472402833403 0.755\n",
      "50 3.351602650938841 0.7575\n",
      "51 3.7649358067924674 0.755\n",
      "52 4.229242874389499 0.7525\n",
      "53 4.750810162102798 0.755\n",
      "54 5.336699231206307 0.7625\n",
      "55 5.994842503189409 0.7625\n",
      "56 6.7341506577508214 0.7625\n",
      "57 7.56463327554629 0.7625\n",
      "58 8.497534359086439 0.76\n",
      "59 9.545484566618338 0.7525\n",
      "60 10.722672220103231 0.755\n",
      "61 12.045035402587823 0.7425\n",
      "62 13.530477745798061 0.7425\n",
      "63 15.199110829529332 0.7425\n",
      "64 17.073526474706906 0.74\n",
      "65 19.179102616724887 0.735\n",
      "66 21.544346900318846 0.7425\n",
      "67 24.20128264794381 0.73\n",
      "68 27.1858824273294 0.715\n",
      "69 30.538555088334157 0.705\n",
      "70 34.30469286314919 0.6775\n",
      "71 38.53528593710527 0.67\n",
      "72 43.28761281083057 0.6325\n",
      "73 48.62601580065353 0.605\n",
      "74 54.62277217684343 0.5825\n",
      "75 61.35907273413169 0.555\n",
      "76 68.92612104349695 0.5425\n",
      "77 77.4263682681127 0.5325\n",
      "78 86.97490026177834 0.5225\n",
      "79 97.70099572992247 0.5125\n",
      "80 109.74987654930568 0.51\n",
      "81 123.28467394420659 0.51\n",
      "82 138.48863713938718 0.505\n",
      "83 155.56761439304722 0.5\n",
      "84 174.7528400007683 0.4975\n",
      "85 196.30406500402725 0.495\n",
      "86 220.51307399030458 0.49\n",
      "87 247.70763559917089 0.49\n",
      "88 278.2559402207126 0.485\n",
      "89 312.5715849688235 0.48\n",
      "90 351.11917342151276 0.48\n",
      "91 394.4206059437656 0.4775\n",
      "92 443.06214575838777 0.48\n",
      "93 497.7023564332114 0.48\n",
      "94 559.0810182512223 0.48\n",
      "95 628.0291441834247 0.48\n",
      "96 705.4802310718645 0.48\n",
      "97 792.482898353917 0.48\n",
      "98 890.2150854450392 0.48\n",
      "99 1000.0 0.48\n"
     ]
    }
   ],
   "source": [
    "# 加了个循环\n",
    "data = np.loadtxt(open(\"w2v_cleaned_mean_shuffle_5000.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "X = data[:, : -1]  # 输入\n",
    "y = data[:, -1]  # 标签\n",
    "rng = np.random.RandomState(2)  # 随机数种子\n",
    "indices = np.arange(len(data))\n",
    "rng.shuffle(indices)  # 将索引打乱\n",
    "train_indices = indices[400:]\n",
    "test_indices = indices[:400]\n",
    "\n",
    "num=100\n",
    "gammas = np.logspace(-2, 3, num=num)\n",
    "for i in range(num):\n",
    "    lp_model = LabelSpreading(gamma=gammas[i], max_iter=30)\n",
    "    lp_model.fit(X[train_indices], y[train_indices])\n",
    "    pred_entropies = stats.distributions.entropy(lp_model.label_distributions_.T)\n",
    "    # print(pred_entropies,len(pred_entropies))\n",
    "    # 选择分类器最不确定的最多5位数字示例\n",
    "    uncertainty_index = np.argsort(pred_entropies)[::-1]\n",
    "    # print(uncertainty_index,len(uncertainty_index))\n",
    "    uncertainty_index = uncertainty_index[\n",
    "    np.in1d(uncertainty_index, train_indices)][:1600]\n",
    "\n",
    "\n",
    "    as_labeled_indices = uncertainty_index # 挑选出的1600个样本作为传播的起点\n",
    "    new_index = np.concatenate((as_labeled_indices, test_indices),axis=0)# 总共的2000样本索引\n",
    "    new_x = X[new_index]\n",
    "    new_y = y[new_index]\n",
    "    new_y[1600:] = -1\n",
    "\n",
    "    lp_model.fit(new_x, new_y)\n",
    "    predicted_labels = lp_model.transduction_[1600:]\n",
    "    true_labels = y[test_indices]\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels,\n",
    "                              labels=lp_model.classes_)\n",
    "\n",
    "    print(i,gammas[i],accuracy_score(true_labels, predicted_labels))\n",
    "    # print(classification_report(true_labels, predicted_labels, digits=4))\n",
    "    # # print(\"Confusion matrix\")\n",
    "    # print(cm)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) 5596\n",
      "train_indices 5196 [2307 2178 1502 ... 2033 1364 4547]\n",
      "[3.67249800e-02 1.77262381e-10 1.05291602e-03 ... 5.59724013e-08\n",
      " 7.13049128e-02 5.59724013e-08] 5196\n",
      "[2854 2754 2306 ...  111   52  100] 5196\n",
      "[2854 2754 2306 ... 4705  882 1391] 1300\n",
      "len(new_x) 2000\n",
      "len(new_y) 2000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8534    0.8250    0.8390       120\n",
      "         1.0     0.8654    0.8654    0.8654       104\n",
      "         2.0     0.7615    0.7615    0.7615       109\n",
      "         3.0     0.7042    0.7463    0.7246        67\n",
      "\n",
      "    accuracy                         0.8050       400\n",
      "   macro avg     0.7961    0.7995    0.7976       400\n",
      "weighted avg     0.8065    0.8050    0.8056       400\n",
      "\n",
      "Confusion matrix\n",
      "[[99 11  8  2]\n",
      " [ 8 90  3  3]\n",
      " [ 8  2 83 16]\n",
      " [ 1  1 15 50]]\n"
     ]
    }
   ],
   "source": [
    "# 修改了model.fit里的条件\n",
    "data = np.loadtxt(open(\"w2v_cleaned_mean_shuffle_5000.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "X = data[:, : -1]  # 输入\n",
    "y = data[:, -1]  # 标签\n",
    "print(\"len(data)\",len(data))\n",
    "rng = np.random.RandomState(8)  # 随机数种子\n",
    "indices = np.arange(len(data))\n",
    "rng.shuffle(indices)  # 将索引打乱\n",
    "train_indices = indices[400:]\n",
    "print(\"train_indices\", len(train_indices), train_indices)\n",
    "test_indices = indices[:400]\n",
    "# print(\"test_indices\", len(test_indices), test_indices)\n",
    "\n",
    "initial_labeled_points = 300\n",
    "unlabeled_indices = train_indices[initial_labeled_points:]\n",
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "y_train[initial_labeled_points:] = -1\n",
    "\n",
    "\n",
    "lp_model = LabelSpreading(gamma=0.79, max_iter=30)# 下一步循环得到最好结果的gamma\n",
    "lp_model.fit(X_train, y_train)\n",
    "pred_entropies = stats.distributions.entropy(lp_model.label_distributions_.T)\n",
    "print(pred_entropies,len(pred_entropies))\n",
    "# 选择分类器最不确定的最多5位数字示例\n",
    "uncertainty_index = np.argsort(pred_entropies)[::-1]\n",
    "print(uncertainty_index,len(uncertainty_index))\n",
    "uncertainty_index = uncertainty_index[\n",
    "np.in1d(uncertainty_index, train_indices[300:])][:1300]\n",
    "print(uncertainty_index,len(uncertainty_index))\n",
    "\n",
    "as_labeled_indices = np.concatenate((train_indices[:300], uncertainty_index),axis=0) # 挑选出的1600个样本作为传播的起点\n",
    "new_index = np.concatenate((as_labeled_indices, test_indices),axis=0)# 总共的2000样本索引\n",
    "new_x = X[new_index]\n",
    "new_y = y[new_index]\n",
    "new_y[1600:] = -1\n",
    "print(\"len(new_x)\",len(new_x))\n",
    "print(\"len(new_y)\",len(new_y))\n",
    "\n",
    "lp_model.fit(new_x, new_y)\n",
    "predicted_labels = lp_model.transduction_[1600:]\n",
    "# print(\"predicted_labels\", predicted_labels)\n",
    "true_labels = y[test_indices]\n",
    "# print(\"true_labels\",true_labels)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels,\n",
    "                          labels=lp_model.classes_)\n",
    "\n",
    "print(classification_report(true_labels, predicted_labels, digits=4))\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 0.39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3510    0.9921    0.5185       127\n",
      "         1.0     0.7317    0.2941    0.4196       102\n",
      "         2.0     0.0000    0.0000    0.0000       113\n",
      "         3.0     0.0000    0.0000    0.0000        58\n",
      "\n",
      "    accuracy                         0.3900       400\n",
      "   macro avg     0.2707    0.3216    0.2345       400\n",
      "weighted avg     0.2980    0.3900    0.2716       400\n",
      "\n",
      "[[126   1   0   0]\n",
      " [ 72  30   0   0]\n",
      " [108   5   0   0]\n",
      " [ 53   5   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.010974987654930561 0.3875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3483    0.9764    0.5135       127\n",
      "         1.0     0.7045    0.3039    0.4247       102\n",
      "         2.0     0.0000    0.0000    0.0000       113\n",
      "         3.0     0.0000    0.0000    0.0000        58\n",
      "\n",
      "    accuracy                         0.3875       400\n",
      "   macro avg     0.2632    0.3201    0.2345       400\n",
      "weighted avg     0.2902    0.3875    0.2713       400\n",
      "\n",
      "[[124   3   0   0]\n",
      " [ 71  31   0   0]\n",
      " [108   5   0   0]\n",
      " [ 53   5   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.012045035402587823 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3705    0.9685    0.5359       127\n",
      "         1.0     0.6909    0.3725    0.4841       102\n",
      "         2.0     0.2308    0.0265    0.0476       113\n",
      "         3.0     0.0000    0.0000    0.0000        58\n",
      "\n",
      "    accuracy                         0.4100       400\n",
      "   macro avg     0.3230    0.3419    0.2669       400\n",
      "weighted avg     0.3590    0.4100    0.3071       400\n",
      "\n",
      "[[123   4   0   0]\n",
      " [ 64  38   0   0]\n",
      " [102   8   3   0]\n",
      " [ 43   5  10   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.013219411484660288 0.4775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4216    0.9528    0.5845       127\n",
      "         1.0     0.6875    0.4314    0.5301       102\n",
      "         2.0     0.5306    0.2301    0.3210       113\n",
      "         3.0     0.0000    0.0000    0.0000        58\n",
      "\n",
      "    accuracy                         0.4775       400\n",
      "   macro avg     0.4099    0.4036    0.3589       400\n",
      "weighted avg     0.4591    0.4775    0.4115       400\n",
      "\n",
      "[[121   6   0   0]\n",
      " [ 58  44   0   0]\n",
      " [ 79   8  26   0]\n",
      " [ 29   6  23   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.014508287784959394 0.53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4821    0.9528    0.6402       127\n",
      "         1.0     0.6849    0.4902    0.5714       102\n",
      "         2.0     0.5395    0.3628    0.4339       113\n",
      "         3.0     0.0000    0.0000    0.0000        58\n",
      "\n",
      "    accuracy                         0.5300       400\n",
      "   macro avg     0.4266    0.4514    0.4114       400\n",
      "weighted avg     0.4801    0.5300    0.4715       400\n",
      "\n",
      "[[121   6   0   0]\n",
      " [ 52  50   0   0]\n",
      " [ 61  11  41   0]\n",
      " [ 17   6  35   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.015922827933410922 0.545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5069    0.8661    0.6395       127\n",
      "         1.0     0.6304    0.5686    0.5979       102\n",
      "         2.0     0.5495    0.4425    0.4902       113\n",
      "         3.0     0.0000    0.0000    0.0000        58\n",
      "\n",
      "    accuracy                         0.5450       400\n",
      "   macro avg     0.4217    0.4693    0.4319       400\n",
      "weighted avg     0.4769    0.5450    0.4940       400\n",
      "\n",
      "[[110  16   1   0]\n",
      " [ 42  58   2   0]\n",
      " [ 51  12  50   0]\n",
      " [ 14   6  38   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.01747528400007684 0.5575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5317    0.8583    0.6566       127\n",
      "         1.0     0.6316    0.5882    0.6091       102\n",
      "         2.0     0.5400    0.4779    0.5070       113\n",
      "         3.0     0.0000    0.0000    0.0000        58\n",
      "\n",
      "    accuracy                         0.5575       400\n",
      "   macro avg     0.4258    0.4811    0.4432       400\n",
      "weighted avg     0.4824    0.5575    0.5070       400\n",
      "\n",
      "[[109  16   2   0]\n",
      " [ 39  60   3   0]\n",
      " [ 46  13  54   0]\n",
      " [ 11   6  41   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.019179102616724886 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6452    0.7874    0.7092       127\n",
      "         1.0     0.6381    0.6569    0.6473       102\n",
      "         2.0     0.5500    0.6814    0.6087       113\n",
      "         3.0     0.0000    0.0000    0.0000        58\n",
      "\n",
      "    accuracy                         0.6100       400\n",
      "   macro avg     0.4583    0.5314    0.4913       400\n",
      "weighted avg     0.5229    0.6100    0.5622       400\n",
      "\n",
      "[[100  18   9   0]\n",
      " [ 27  67   8   0]\n",
      " [ 22  14  77   0]\n",
      " [  6   6  46   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.02104904144512021 0.615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6621    0.7559    0.7059       127\n",
      "         1.0     0.6389    0.6765    0.6571       102\n",
      "         2.0     0.5479    0.7080    0.6178       113\n",
      "         3.0     1.0000    0.0172    0.0339        58\n",
      "\n",
      "    accuracy                         0.6150       400\n",
      "   macro avg     0.7122    0.5394    0.5037       400\n",
      "weighted avg     0.6729    0.6150    0.5711       400\n",
      "\n",
      "[[96 19 12  0]\n",
      " [24 69  9  0]\n",
      " [19 14 80  0]\n",
      " [ 6  6 45  1]]\n",
      "9 0.023101297000831605 0.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7111    0.7559    0.7328       127\n",
      "         1.0     0.6486    0.7059    0.6761       102\n",
      "         2.0     0.5608    0.7345    0.6360       113\n",
      "         3.0     0.8333    0.0862    0.1563        58\n",
      "\n",
      "    accuracy                         0.6400       400\n",
      "   macro avg     0.6885    0.5706    0.5503       400\n",
      "weighted avg     0.6704    0.6400    0.6074       400\n",
      "\n",
      "[[96 19 12  0]\n",
      " [20 72 10  0]\n",
      " [15 14 83  1]\n",
      " [ 4  6 43  5]]\n",
      "10 0.025353644939701114 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7302    0.7244    0.7273       127\n",
      "         1.0     0.6372    0.7059    0.6698       102\n",
      "         2.0     0.5782    0.7522    0.6538       113\n",
      "         3.0     0.9286    0.2241    0.3611        58\n",
      "\n",
      "    accuracy                         0.6550       400\n",
      "   macro avg     0.7185    0.6017    0.6030       400\n",
      "weighted avg     0.6923    0.6550    0.6388       400\n",
      "\n",
      "[[92 20 15  0]\n",
      " [18 72 12  0]\n",
      " [12 15 85  1]\n",
      " [ 4  6 35 13]]\n",
      "11 0.027825594022071243 0.6575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7419    0.7244    0.7331       127\n",
      "         1.0     0.6372    0.7059    0.6698       102\n",
      "         2.0     0.5816    0.7257    0.6457       113\n",
      "         3.0     0.7727    0.2931    0.4250        58\n",
      "\n",
      "    accuracy                         0.6575       400\n",
      "   macro avg     0.6833    0.6123    0.6184       400\n",
      "weighted avg     0.6744    0.6575    0.6476       400\n",
      "\n",
      "[[92 20 15  0]\n",
      " [18 72 12  0]\n",
      " [11 15 82  5]\n",
      " [ 3  6 32 17]]\n",
      "12 0.030538555088334154 0.675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7541    0.7244    0.7390       127\n",
      "         1.0     0.6372    0.7059    0.6698       102\n",
      "         2.0     0.6124    0.6991    0.6529       113\n",
      "         3.0     0.7500    0.4655    0.5745        58\n",
      "\n",
      "    accuracy                         0.6750       400\n",
      "   macro avg     0.6884    0.6487    0.6590       400\n",
      "weighted avg     0.6837    0.6750    0.6731       400\n",
      "\n",
      "[[92 20 15  0]\n",
      " [18 72 12  0]\n",
      " [10 15 79  9]\n",
      " [ 2  6 23 27]]\n",
      "13 0.033516026509388425 0.6825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7583    0.7165    0.7368       127\n",
      "         1.0     0.6348    0.7157    0.6728       102\n",
      "         2.0     0.6290    0.6903    0.6582       113\n",
      "         3.0     0.7561    0.5345    0.6263        58\n",
      "\n",
      "    accuracy                         0.6825       400\n",
      "   macro avg     0.6946    0.6642    0.6735       400\n",
      "weighted avg     0.6900    0.6825    0.6823       400\n",
      "\n",
      "[[91 21 15  0]\n",
      " [17 73 12  0]\n",
      " [10 15 78 10]\n",
      " [ 2  6 19 31]]\n",
      "14 0.03678379771828634 0.685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7563    0.7087    0.7317       127\n",
      "         1.0     0.6348    0.7157    0.6728       102\n",
      "         2.0     0.6435    0.6549    0.6491       113\n",
      "         3.0     0.7255    0.6379    0.6789        58\n",
      "\n",
      "    accuracy                         0.6850       400\n",
      "   macro avg     0.6900    0.6793    0.6831       400\n",
      "weighted avg     0.6890    0.6850    0.6857       400\n",
      "\n",
      "[[90 21 16  0]\n",
      " [17 73 12  0]\n",
      " [10 15 74 14]\n",
      " [ 2  6 13 37]]\n",
      "15 0.040370172585965536 0.6925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7581    0.7402    0.7490       127\n",
      "         1.0     0.6697    0.7157    0.6919       102\n",
      "         2.0     0.6460    0.6460    0.6460       113\n",
      "         3.0     0.6852    0.6379    0.6607        58\n",
      "\n",
      "    accuracy                         0.6925       400\n",
      "   macro avg     0.6897    0.6849    0.6869       400\n",
      "weighted avg     0.6933    0.6925    0.6926       400\n",
      "\n",
      "[[94 17 15  1]\n",
      " [17 73 12  0]\n",
      " [11 13 73 16]\n",
      " [ 2  6 13 37]]\n",
      "16 0.044306214575838825 0.7075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7750    0.7323    0.7530       127\n",
      "         1.0     0.7115    0.7255    0.7184       102\n",
      "         2.0     0.6486    0.6372    0.6429       113\n",
      "         3.0     0.6769    0.7586    0.7154        58\n",
      "\n",
      "    accuracy                         0.7075       400\n",
      "   macro avg     0.7030    0.7134    0.7074       400\n",
      "weighted avg     0.7089    0.7075    0.7076       400\n",
      "\n",
      "[[93 18 14  2]\n",
      " [15 74 13  0]\n",
      " [11 11 72 19]\n",
      " [ 1  1 12 44]]\n",
      "17 0.04862601580065353 0.7125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7705    0.7402    0.7550       127\n",
      "         1.0     0.7157    0.7157    0.7157       102\n",
      "         2.0     0.6491    0.6549    0.6520       113\n",
      "         3.0     0.7097    0.7586    0.7333        58\n",
      "\n",
      "    accuracy                         0.7125       400\n",
      "   macro avg     0.7112    0.7173    0.7140       400\n",
      "weighted avg     0.7134    0.7125    0.7127       400\n",
      "\n",
      "[[94 17 15  1]\n",
      " [16 73 13  0]\n",
      " [11 11 74 17]\n",
      " [ 1  1 12 44]]\n",
      "18 0.0533669923120631 0.7025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7642    0.7402    0.7520       127\n",
      "         1.0     0.7129    0.7059    0.7094       102\n",
      "         2.0     0.6396    0.6283    0.6339       113\n",
      "         3.0     0.6769    0.7586    0.7154        58\n",
      "\n",
      "    accuracy                         0.7025       400\n",
      "   macro avg     0.6984    0.7082    0.7027       400\n",
      "weighted avg     0.7033    0.7025    0.7025       400\n",
      "\n",
      "[[94 17 15  1]\n",
      " [17 72 13  0]\n",
      " [11 11 71 20]\n",
      " [ 1  1 12 44]]\n",
      "19 0.05857020818056667 0.6975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7642    0.7402    0.7520       127\n",
      "         1.0     0.7200    0.7059    0.7129       102\n",
      "         2.0     0.6476    0.6018    0.6239       113\n",
      "         3.0     0.6250    0.7759    0.6923        58\n",
      "\n",
      "    accuracy                         0.6975       400\n",
      "   macro avg     0.6892    0.7059    0.6953       400\n",
      "weighted avg     0.6998    0.6975    0.6972       400\n",
      "\n",
      "[[94 17 13  3]\n",
      " [17 72 13  0]\n",
      " [11 10 68 24]\n",
      " [ 1  1 11 45]]\n",
      "20 0.06428073117284322 0.705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7787    0.7480    0.7631       127\n",
      "         1.0     0.7300    0.7157    0.7228       102\n",
      "         2.0     0.6538    0.6018    0.6267       113\n",
      "         3.0     0.6216    0.7931    0.6970        58\n",
      "\n",
      "    accuracy                         0.7050       400\n",
      "   macro avg     0.6960    0.7146    0.7024       400\n",
      "weighted avg     0.7082    0.7050    0.7047       400\n",
      "\n",
      "[[95 16 13  3]\n",
      " [15 73 13  1]\n",
      " [11 10 68 24]\n",
      " [ 1  1 10 46]]\n",
      "21 0.07054802310718646 0.705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7851    0.7480    0.7661       127\n",
      "         1.0     0.7475    0.7255    0.7363       102\n",
      "         2.0     0.6408    0.5841    0.6111       113\n",
      "         3.0     0.6104    0.8103    0.6963        58\n",
      "\n",
      "    accuracy                         0.7050       400\n",
      "   macro avg     0.6959    0.7170    0.7025       400\n",
      "weighted avg     0.7094    0.7050    0.7046       400\n",
      "\n",
      "[[95 16 14  2]\n",
      " [14 74 13  1]\n",
      " [11  9 66 27]\n",
      " [ 1  0 10 47]]\n",
      "22 0.0774263682681127 0.705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7917    0.7480    0.7692       127\n",
      "         1.0     0.7500    0.7353    0.7426       102\n",
      "         2.0     0.6311    0.5752    0.6019       113\n",
      "         3.0     0.6104    0.8103    0.6963        58\n",
      "\n",
      "    accuracy                         0.7050       400\n",
      "   macro avg     0.6958    0.7172    0.7025       400\n",
      "weighted avg     0.7094    0.7050    0.7046       400\n",
      "\n",
      "[[95 16 15  1]\n",
      " [13 75 13  1]\n",
      " [11  9 65 28]\n",
      " [ 1  0 10 47]]\n",
      "23 0.08497534359086446 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7949    0.7323    0.7623       127\n",
      "         1.0     0.7500    0.7353    0.7426       102\n",
      "         2.0     0.6250    0.5752    0.5991       113\n",
      "         3.0     0.5949    0.8103    0.6861        58\n",
      "\n",
      "    accuracy                         0.7000       400\n",
      "   macro avg     0.6912    0.7133    0.6975       400\n",
      "weighted avg     0.7065    0.7000    0.7001       400\n",
      "\n",
      "[[93 16 15  3]\n",
      " [12 75 14  1]\n",
      " [11  9 65 28]\n",
      " [ 1  0 10 47]]\n",
      "24 0.093260334688322 0.7075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7983    0.7480    0.7724       127\n",
      "         1.0     0.7576    0.7353    0.7463       102\n",
      "         2.0     0.6408    0.5841    0.6111       113\n",
      "         3.0     0.5949    0.8103    0.6861        58\n",
      "\n",
      "    accuracy                         0.7075       400\n",
      "   macro avg     0.6979    0.7194    0.7040       400\n",
      "weighted avg     0.7139    0.7075    0.7077       400\n",
      "\n",
      "[[95 16 13  3]\n",
      " [12 75 14  1]\n",
      " [11  8 66 28]\n",
      " [ 1  0 10 47]]\n",
      "25 0.10235310218990264 0.7025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8103    0.7402    0.7737       127\n",
      "         1.0     0.7576    0.7353    0.7463       102\n",
      "         2.0     0.6132    0.5752    0.5936       113\n",
      "         3.0     0.5949    0.8103    0.6861        58\n",
      "\n",
      "    accuracy                         0.7025       400\n",
      "   macro avg     0.6940    0.7153    0.6999       400\n",
      "weighted avg     0.7100    0.7025    0.7031       400\n",
      "\n",
      "[[94 16 16  1]\n",
      " [11 75 15  1]\n",
      " [10  8 65 30]\n",
      " [ 1  0 10 47]]\n",
      "26 0.11233240329780277 0.715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8333    0.7480    0.7884       127\n",
      "         1.0     0.7677    0.7451    0.7562       102\n",
      "         2.0     0.6182    0.6018    0.6099       113\n",
      "         3.0     0.6104    0.8103    0.6963        58\n",
      "\n",
      "    accuracy                         0.7150       400\n",
      "   macro avg     0.7074    0.7263    0.7127       400\n",
      "weighted avg     0.7235    0.7150    0.7164       400\n",
      "\n",
      "[[95 16 15  1]\n",
      " [ 9 76 16  1]\n",
      " [10  7 68 28]\n",
      " [ 0  0 11 47]]\n",
      "27 0.12328467394420665 0.7125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8304    0.7323    0.7782       127\n",
      "         1.0     0.7677    0.7451    0.7562       102\n",
      "         2.0     0.6053    0.6106    0.6079       113\n",
      "         3.0     0.6267    0.8103    0.7068        58\n",
      "\n",
      "    accuracy                         0.7125       400\n",
      "   macro avg     0.7075    0.7246    0.7123       400\n",
      "weighted avg     0.7212    0.7125    0.7141       400\n",
      "\n",
      "[[93 16 17  1]\n",
      " [ 9 76 17  0]\n",
      " [10  7 69 27]\n",
      " [ 0  0 11 47]]\n",
      "28 0.13530477745798075 0.715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8319    0.7402    0.7833       127\n",
      "         1.0     0.7677    0.7451    0.7562       102\n",
      "         2.0     0.6182    0.6018    0.6099       113\n",
      "         3.0     0.6154    0.8276    0.7059        58\n",
      "\n",
      "    accuracy                         0.7150       400\n",
      "   macro avg     0.7083    0.7287    0.7138       400\n",
      "weighted avg     0.7237    0.7150    0.7162       400\n",
      "\n",
      "[[94 16 16  1]\n",
      " [ 9 76 16  1]\n",
      " [10  7 68 28]\n",
      " [ 0  0 10 48]]\n",
      "29 0.1484968262254465 0.715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8333    0.7480    0.7884       127\n",
      "         1.0     0.7895    0.7353    0.7614       102\n",
      "         2.0     0.6182    0.6018    0.6099       113\n",
      "         3.0     0.5926    0.8276    0.6906        58\n",
      "\n",
      "    accuracy                         0.7150       400\n",
      "   macro avg     0.7084    0.7282    0.7126       400\n",
      "weighted avg     0.7265    0.7150    0.7169       400\n",
      "\n",
      "[[95 13 18  1]\n",
      " [ 9 75 14  4]\n",
      " [10  7 68 28]\n",
      " [ 0  0 10 48]]\n",
      "30 0.16297508346206444 0.7125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8230    0.7323    0.7750       127\n",
      "         1.0     0.7732    0.7353    0.7538       102\n",
      "         2.0     0.6273    0.6106    0.6188       113\n",
      "         3.0     0.6000    0.8276    0.6957        58\n",
      "\n",
      "    accuracy                         0.7125       400\n",
      "   macro avg     0.7059    0.7264    0.7108       400\n",
      "weighted avg     0.7227    0.7125    0.7140       400\n",
      "\n",
      "[[93 16 17  1]\n",
      " [ 9 75 14  4]\n",
      " [11  6 69 27]\n",
      " [ 0  0 10 48]]\n",
      "31 0.1788649529057435 0.7325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8448    0.7717    0.8066       127\n",
      "         1.0     0.8085    0.7451    0.7755       102\n",
      "         2.0     0.6455    0.6283    0.6368       113\n",
      "         3.0     0.6000    0.8276    0.6957        58\n",
      "\n",
      "    accuracy                         0.7325       400\n",
      "   macro avg     0.7247    0.7432    0.7286       400\n",
      "weighted avg     0.7437    0.7325    0.7346       400\n",
      "\n",
      "[[98 13 16  0]\n",
      " [ 8 76 13  5]\n",
      " [10  5 71 27]\n",
      " [ 0  0 10 48]]\n",
      "32 0.19630406500402714 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8468    0.7402    0.7899       127\n",
      "         1.0     0.8000    0.7451    0.7716       102\n",
      "         2.0     0.6325    0.6549    0.6435       113\n",
      "         3.0     0.6234    0.8276    0.7111        58\n",
      "\n",
      "    accuracy                         0.7300       400\n",
      "   macro avg     0.7257    0.7419    0.7290       400\n",
      "weighted avg     0.7419    0.7300    0.7324       400\n",
      "\n",
      "[[94 13 20  0]\n",
      " [ 8 76 13  5]\n",
      " [ 9  6 74 24]\n",
      " [ 0  0 10 48]]\n",
      "33 0.21544346900318845 0.7375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8496    0.7559    0.8000       127\n",
      "         1.0     0.8021    0.7549    0.7778       102\n",
      "         2.0     0.6435    0.6549    0.6491       113\n",
      "         3.0     0.6316    0.8276    0.7164        58\n",
      "\n",
      "    accuracy                         0.7375       400\n",
      "   macro avg     0.7317    0.7483    0.7358       400\n",
      "weighted avg     0.7476    0.7375    0.7396       400\n",
      "\n",
      "[[96 13 18  0]\n",
      " [ 8 77 13  4]\n",
      " [ 9  6 74 24]\n",
      " [ 0  0 10 48]]\n",
      "34 0.23644894126454083 0.7575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8750    0.7717    0.8201       127\n",
      "         1.0     0.8247    0.7843    0.8040       102\n",
      "         2.0     0.6667    0.6726    0.6696       113\n",
      "         3.0     0.6364    0.8448    0.7259        58\n",
      "\n",
      "    accuracy                         0.7575       400\n",
      "   macro avg     0.7507    0.7683    0.7549       400\n",
      "weighted avg     0.7687    0.7575    0.7598       400\n",
      "\n",
      "[[98 12 17  0]\n",
      " [ 6 80 12  4]\n",
      " [ 8  5 76 24]\n",
      " [ 0  0  9 49]]\n",
      "35 0.25950242113997374 0.7625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8818    0.7638    0.8186       127\n",
      "         1.0     0.8333    0.7843    0.8081       102\n",
      "         2.0     0.6783    0.6903    0.6842       113\n",
      "         3.0     0.6329    0.8621    0.7299        58\n",
      "\n",
      "    accuracy                         0.7625       400\n",
      "   macro avg     0.7566    0.7751    0.7602       400\n",
      "weighted avg     0.7759    0.7625    0.7651       400\n",
      "\n",
      "[[97 12 18  0]\n",
      " [ 6 80 11  5]\n",
      " [ 7  4 78 24]\n",
      " [ 0  0  8 50]]\n",
      "36 0.2848035868435802 0.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8750    0.7717    0.8201       127\n",
      "         1.0     0.8229    0.7745    0.7980       102\n",
      "         2.0     0.6964    0.6903    0.6933       113\n",
      "         3.0     0.6125    0.8448    0.7101        58\n",
      "\n",
      "    accuracy                         0.7600       400\n",
      "   macro avg     0.7517    0.7703    0.7554       400\n",
      "weighted avg     0.7732    0.7600    0.7627       400\n",
      "\n",
      "[[98 13 16  0]\n",
      " [ 7 79 10  6]\n",
      " [ 6  4 78 25]\n",
      " [ 1  0  8 49]]\n",
      "37 0.3125715849688237 0.7575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8750    0.7717    0.8201       127\n",
      "         1.0     0.7980    0.7745    0.7861       102\n",
      "         2.0     0.7027    0.6903    0.6964       113\n",
      "         3.0     0.6154    0.8276    0.7059        58\n",
      "\n",
      "    accuracy                         0.7575       400\n",
      "   macro avg     0.7478    0.7660    0.7521       400\n",
      "weighted avg     0.7690    0.7575    0.7599       400\n",
      "\n",
      "[[98 14 15  0]\n",
      " [ 7 79  9  7]\n",
      " [ 6  6 78 23]\n",
      " [ 1  0  9 48]]\n",
      "38 0.34304692863149194 0.7525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8661    0.7638    0.8117       127\n",
      "         1.0     0.7980    0.7745    0.7861       102\n",
      "         2.0     0.7091    0.6903    0.6996       113\n",
      "         3.0     0.5949    0.8103    0.6861        58\n",
      "\n",
      "    accuracy                         0.7525       400\n",
      "   macro avg     0.7420    0.7597    0.7459       400\n",
      "weighted avg     0.7650    0.7525    0.7553       400\n",
      "\n",
      "[[97 15 15  0]\n",
      " [ 8 79  7  8]\n",
      " [ 6  5 78 24]\n",
      " [ 1  0 10 47]]\n",
      "39 0.37649358067924693 0.745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8496    0.7559    0.8000       127\n",
      "         1.0     0.7800    0.7647    0.7723       102\n",
      "         2.0     0.7000    0.6814    0.6906       113\n",
      "         3.0     0.6104    0.8103    0.6963        58\n",
      "\n",
      "    accuracy                         0.7450       400\n",
      "   macro avg     0.7350    0.7531    0.7398       400\n",
      "weighted avg     0.7549    0.7450    0.7470       400\n",
      "\n",
      "[[96 15 16  0]\n",
      " [10 78  7  7]\n",
      " [ 6  7 77 23]\n",
      " [ 1  0 10 47]]\n",
      "40 0.41320124001153385 0.7425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8435    0.7638    0.8017       127\n",
      "         1.0     0.7677    0.7451    0.7562       102\n",
      "         2.0     0.7196    0.6814    0.7000       113\n",
      "         3.0     0.5949    0.8103    0.6861        58\n",
      "\n",
      "    accuracy                         0.7425       400\n",
      "   macro avg     0.7314    0.7502    0.7360       400\n",
      "weighted avg     0.7531    0.7425    0.7446       400\n",
      "\n",
      "[[97 16 13  1]\n",
      " [11 76  7  8]\n",
      " [ 6  7 77 23]\n",
      " [ 1  0 10 47]]\n",
      "41 0.4534878508128584 0.7375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8448    0.7717    0.8066       127\n",
      "         1.0     0.7778    0.7549    0.7662       102\n",
      "         2.0     0.6981    0.6549    0.6758       113\n",
      "         3.0     0.5823    0.7931    0.6715        58\n",
      "\n",
      "    accuracy                         0.7375       400\n",
      "   macro avg     0.7257    0.7436    0.7300       400\n",
      "weighted avg     0.7482    0.7375    0.7397       400\n",
      "\n",
      "[[98 14 14  1]\n",
      " [10 77  7  8]\n",
      " [ 7  8 74 24]\n",
      " [ 1  0 11 46]]\n",
      "42 0.49770235643321115 0.7375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8376    0.7717    0.8033       127\n",
      "         1.0     0.7778    0.7549    0.7662       102\n",
      "         2.0     0.6852    0.6549    0.6697       113\n",
      "         3.0     0.6053    0.7931    0.6866        58\n",
      "\n",
      "    accuracy                         0.7375       400\n",
      "   macro avg     0.7265    0.7436    0.7314       400\n",
      "weighted avg     0.7456    0.7375    0.7392       400\n",
      "\n",
      "[[98 14 15  0]\n",
      " [11 77  8  6]\n",
      " [ 7  8 74 24]\n",
      " [ 1  0 11 46]]\n",
      "43 0.5462277217684343 0.7425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8291    0.7638    0.7951       127\n",
      "         1.0     0.7959    0.7647    0.7800       102\n",
      "         2.0     0.6972    0.6726    0.6847       113\n",
      "         3.0     0.6053    0.7931    0.6866        58\n",
      "\n",
      "    accuracy                         0.7425       400\n",
      "   macro avg     0.7319    0.7485    0.7366       400\n",
      "weighted avg     0.7509    0.7425    0.7443       400\n",
      "\n",
      "[[97 15 15  0]\n",
      " [11 78  7  6]\n",
      " [ 8  5 76 24]\n",
      " [ 1  0 11 46]]\n",
      "44 0.5994842503189411 0.7325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8205    0.7559    0.7869       127\n",
      "         1.0     0.7879    0.7647    0.7761       102\n",
      "         2.0     0.6881    0.6637    0.6757       113\n",
      "         3.0     0.5867    0.7586    0.6617        58\n",
      "\n",
      "    accuracy                         0.7325       400\n",
      "   macro avg     0.7208    0.7357    0.7251       400\n",
      "weighted avg     0.7409    0.7325    0.7346       400\n",
      "\n",
      "[[96 16 15  0]\n",
      " [11 78  7  6]\n",
      " [ 8  5 75 25]\n",
      " [ 2  0 12 44]]\n",
      "45 0.6579332246575682 0.7275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8136    0.7559    0.7837       127\n",
      "         1.0     0.7980    0.7745    0.7861       102\n",
      "         2.0     0.6667    0.6372    0.6516       113\n",
      "         3.0     0.5867    0.7586    0.6617        58\n",
      "\n",
      "    accuracy                         0.7275       400\n",
      "   macro avg     0.7162    0.7316    0.7207       400\n",
      "weighted avg     0.7352    0.7275    0.7293       400\n",
      "\n",
      "[[96 15 16  0]\n",
      " [11 79  8  4]\n",
      " [ 9  5 72 27]\n",
      " [ 2  0 12 44]]\n",
      "46 0.7220809018385468 0.7175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7851    0.7480    0.7661       127\n",
      "         1.0     0.7879    0.7647    0.7761       102\n",
      "         2.0     0.6542    0.6195    0.6364       113\n",
      "         3.0     0.6027    0.7586    0.6718        58\n",
      "\n",
      "    accuracy                         0.7175       400\n",
      "   macro avg     0.7075    0.7227    0.7126       400\n",
      "weighted avg     0.7224    0.7175    0.7183       400\n",
      "\n",
      "[[95 15 17  0]\n",
      " [12 78  8  4]\n",
      " [12  6 70 25]\n",
      " [ 2  0 12 44]]\n",
      "47 0.7924828983539177 0.715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7787    0.7480    0.7631       127\n",
      "         1.0     0.7959    0.7647    0.7800       102\n",
      "         2.0     0.6509    0.6106    0.6301       113\n",
      "         3.0     0.5946    0.7586    0.6667        58\n",
      "\n",
      "    accuracy                         0.7150       400\n",
      "   macro avg     0.7050    0.7205    0.7100       400\n",
      "weighted avg     0.7203    0.7150    0.7158       400\n",
      "\n",
      "[[95 14 18  0]\n",
      " [13 78  7  4]\n",
      " [12  6 69 26]\n",
      " [ 2  0 12 44]]\n",
      "48 0.8697490026177834 0.715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7742    0.7559    0.7649       127\n",
      "         1.0     0.7980    0.7745    0.7861       102\n",
      "         2.0     0.6442    0.5929    0.6175       113\n",
      "         3.0     0.6027    0.7586    0.6718        58\n",
      "\n",
      "    accuracy                         0.7150       400\n",
      "   macro avg     0.7048    0.7205    0.7101       400\n",
      "weighted avg     0.7187    0.7150    0.7152       400\n",
      "\n",
      "[[96 13 18  0]\n",
      " [12 79  7  4]\n",
      " [14  7 67 25]\n",
      " [ 2  0 12 44]]\n",
      "49 0.9545484566618342 0.725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7760    0.7638    0.7698       127\n",
      "         1.0     0.8061    0.7745    0.7900       102\n",
      "         2.0     0.6667    0.6018    0.6326       113\n",
      "         3.0     0.6133    0.7931    0.6917        58\n",
      "\n",
      "    accuracy                         0.7250       400\n",
      "   macro avg     0.7155    0.7333    0.7210       400\n",
      "weighted avg     0.7292    0.7250    0.7249       400\n",
      "\n",
      "[[97 13 17  0]\n",
      " [13 79  7  3]\n",
      " [13  6 68 26]\n",
      " [ 2  0 10 46]]\n",
      "50 1.0476157527896652 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7742    0.7559    0.7649       127\n",
      "         1.0     0.8061    0.7745    0.7900       102\n",
      "         2.0     0.6538    0.6018    0.6267       113\n",
      "         3.0     0.6081    0.7759    0.6818        58\n",
      "\n",
      "    accuracy                         0.7200       400\n",
      "   macro avg     0.7106    0.7270    0.7159       400\n",
      "weighted avg     0.7243    0.7200    0.7202       400\n",
      "\n",
      "[[96 13 18  0]\n",
      " [13 79  7  3]\n",
      " [13  6 68 26]\n",
      " [ 2  0 11 45]]\n",
      "51 1.149756995397737 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7742    0.7559    0.7649       127\n",
      "         1.0     0.8061    0.7745    0.7900       102\n",
      "         2.0     0.6571    0.6106    0.6330       113\n",
      "         3.0     0.6027    0.7586    0.6718        58\n",
      "\n",
      "    accuracy                         0.7200       400\n",
      "   macro avg     0.7100    0.7249    0.7149       400\n",
      "weighted avg     0.7244    0.7200    0.7206       400\n",
      "\n",
      "[[96 13 18  0]\n",
      " [13 79  6  4]\n",
      " [13  6 69 25]\n",
      " [ 2  0 12 44]]\n",
      "52 1.261856883066021 0.7175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7661    0.7480    0.7570       127\n",
      "         1.0     0.7980    0.7745    0.7861       102\n",
      "         2.0     0.6667    0.6018    0.6326       113\n",
      "         3.0     0.6000    0.7759    0.6767        58\n",
      "\n",
      "    accuracy                         0.7175       400\n",
      "   macro avg     0.7077    0.7250    0.7131       400\n",
      "weighted avg     0.7221    0.7175    0.7176       400\n",
      "\n",
      "[[95 14 17  1]\n",
      " [13 79  6  4]\n",
      " [14  6 68 25]\n",
      " [ 2  0 11 45]]\n",
      "53 1.384886371393873 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7480    0.7480    0.7480       127\n",
      "         1.0     0.8061    0.7745    0.7900       102\n",
      "         2.0     0.6566    0.5752    0.6132       113\n",
      "         3.0     0.5921    0.7759    0.6716        58\n",
      "\n",
      "    accuracy                         0.7100       400\n",
      "   macro avg     0.7007    0.7184    0.7057       400\n",
      "weighted avg     0.7144    0.7100    0.7096       400\n",
      "\n",
      "[[95 14 17  1]\n",
      " [13 79  6  4]\n",
      " [17  5 65 26]\n",
      " [ 2  0 11 45]]\n",
      "54 1.5199110829529348 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7442    0.7559    0.7500       127\n",
      "         1.0     0.8125    0.7647    0.7879       102\n",
      "         2.0     0.6633    0.5752    0.6161       113\n",
      "         3.0     0.5844    0.7759    0.6667        58\n",
      "\n",
      "    accuracy                         0.7100       400\n",
      "   macro avg     0.7011    0.7179    0.7052       400\n",
      "weighted avg     0.7156    0.7100    0.7098       400\n",
      "\n",
      "[[96 14 16  1]\n",
      " [13 78  6  5]\n",
      " [18  4 65 26]\n",
      " [ 2  0 11 45]]\n",
      "55 1.6681005372000592 0.725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7698    0.7638    0.7668       127\n",
      "         1.0     0.8298    0.7647    0.7959       102\n",
      "         2.0     0.6733    0.6018    0.6355       113\n",
      "         3.0     0.5949    0.8103    0.6861        58\n",
      "\n",
      "    accuracy                         0.7250       400\n",
      "   macro avg     0.7170    0.7352    0.7211       400\n",
      "weighted avg     0.7325    0.7250    0.7254       400\n",
      "\n",
      "[[97 13 17  0]\n",
      " [11 78  7  6]\n",
      " [16  3 68 26]\n",
      " [ 2  0  9 47]]\n",
      "56 1.8307382802953698 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7742    0.7559    0.7649       127\n",
      "         1.0     0.8280    0.7549    0.7897       102\n",
      "         2.0     0.6604    0.6195    0.6393       113\n",
      "         3.0     0.5844    0.7759    0.6667        58\n",
      "\n",
      "    accuracy                         0.7200       400\n",
      "   macro avg     0.7117    0.7265    0.7152       400\n",
      "weighted avg     0.7282    0.7200    0.7215       400\n",
      "\n",
      "[[96 13 18  0]\n",
      " [12 77  7  6]\n",
      " [14  3 70 26]\n",
      " [ 2  0 11 45]]\n",
      "57 2.0092330025650478 0.7175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7851    0.7480    0.7661       127\n",
      "         1.0     0.8211    0.7647    0.7919       102\n",
      "         2.0     0.6389    0.6106    0.6244       113\n",
      "         3.0     0.5921    0.7759    0.6716        58\n",
      "\n",
      "    accuracy                         0.7175       400\n",
      "   macro avg     0.7093    0.7248    0.7135       400\n",
      "weighted avg     0.7250    0.7175    0.7190       400\n",
      "\n",
      "[[95 14 18  0]\n",
      " [11 78  9  4]\n",
      " [14  3 69 27]\n",
      " [ 1  0 12 45]]\n",
      "58 2.2051307399030455 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7805    0.7559    0.7680       127\n",
      "         1.0     0.8211    0.7647    0.7919       102\n",
      "         2.0     0.6286    0.5841    0.6055       113\n",
      "         3.0     0.5714    0.7586    0.6519        58\n",
      "\n",
      "    accuracy                         0.7100       400\n",
      "   macro avg     0.7004    0.7158    0.7043       400\n",
      "weighted avg     0.7176    0.7100    0.7113       400\n",
      "\n",
      "[[96 14 17  0]\n",
      " [11 78  9  4]\n",
      " [15  3 66 29]\n",
      " [ 1  0 13 44]]\n",
      "59 2.4201282647943834 0.7075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7760    0.7638    0.7698       127\n",
      "         1.0     0.8280    0.7549    0.7897       102\n",
      "         2.0     0.6226    0.5841    0.6027       113\n",
      "         3.0     0.5658    0.7414    0.6418        58\n",
      "\n",
      "    accuracy                         0.7075       400\n",
      "   macro avg     0.6981    0.7110    0.7010       400\n",
      "weighted avg     0.7154    0.7075    0.7091       400\n",
      "\n",
      "[[97 13 17  0]\n",
      " [12 77  9  4]\n",
      " [15  3 66 29]\n",
      " [ 1  0 14 43]]\n",
      "60 2.656087782946687 0.695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7869    0.7559    0.7711       127\n",
      "         1.0     0.7917    0.7451    0.7677       102\n",
      "         2.0     0.5926    0.5664    0.5792       113\n",
      "         3.0     0.5676    0.7241    0.6364        58\n",
      "\n",
      "    accuracy                         0.6950       400\n",
      "   macro avg     0.6847    0.6979    0.6886       400\n",
      "weighted avg     0.7014    0.6950    0.6965       400\n",
      "\n",
      "[[96 13 18  0]\n",
      " [12 76 11  3]\n",
      " [13  7 64 29]\n",
      " [ 1  0 15 42]]\n",
      "61 2.9150530628251787 0.6975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7934    0.7559    0.7742       127\n",
      "         1.0     0.7938    0.7549    0.7739       102\n",
      "         2.0     0.5926    0.5664    0.5792       113\n",
      "         3.0     0.5676    0.7241    0.6364        58\n",
      "\n",
      "    accuracy                         0.6975       400\n",
      "   macro avg     0.6868    0.7003    0.6909       400\n",
      "weighted avg     0.7040    0.6975    0.6990       400\n",
      "\n",
      "[[96 13 18  0]\n",
      " [11 77 11  3]\n",
      " [13  7 64 29]\n",
      " [ 1  0 15 42]]\n",
      "62 3.1992671377973845 0.6925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7934    0.7559    0.7742       127\n",
      "         1.0     0.7959    0.7647    0.7800       102\n",
      "         2.0     0.5810    0.5398    0.5596       113\n",
      "         3.0     0.5526    0.7241    0.6269        58\n",
      "\n",
      "    accuracy                         0.6925       400\n",
      "   macro avg     0.6807    0.6961    0.6852       400\n",
      "weighted avg     0.6991    0.6925    0.6937       400\n",
      "\n",
      "[[96 13 18  0]\n",
      " [10 78 11  3]\n",
      " [14  7 61 31]\n",
      " [ 1  0 15 42]]\n",
      "63 3.5111917342151346 0.6975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7917    0.7480    0.7692       127\n",
      "         1.0     0.7800    0.7647    0.7723       102\n",
      "         2.0     0.6058    0.5575    0.5806       113\n",
      "         3.0     0.5658    0.7414    0.6418        58\n",
      "\n",
      "    accuracy                         0.6975       400\n",
      "   macro avg     0.6858    0.7029    0.6910       400\n",
      "weighted avg     0.7034    0.6975    0.6983       400\n",
      "\n",
      "[[95 15 17  0]\n",
      " [11 78 10  3]\n",
      " [13  7 63 30]\n",
      " [ 1  0 14 43]]\n",
      "64 3.8535285937105312 0.6975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8051    0.7480    0.7755       127\n",
      "         1.0     0.7900    0.7745    0.7822       102\n",
      "         2.0     0.5905    0.5487    0.5688       113\n",
      "         3.0     0.5584    0.7414    0.6370        58\n",
      "\n",
      "    accuracy                         0.6975       400\n",
      "   macro avg     0.6860    0.7031    0.6909       400\n",
      "weighted avg     0.7048    0.6975    0.6987       400\n",
      "\n",
      "[[95 14 18  0]\n",
      " [10 79 10  3]\n",
      " [13  7 62 31]\n",
      " [ 0  0 15 43]]\n",
      "65 4.229242874389499 0.6975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8120    0.7480    0.7787       127\n",
      "         1.0     0.7822    0.7745    0.7783       102\n",
      "         2.0     0.5905    0.5487    0.5688       113\n",
      "         3.0     0.5584    0.7414    0.6370        58\n",
      "\n",
      "    accuracy                         0.6975       400\n",
      "   macro avg     0.6858    0.7031    0.6907       400\n",
      "weighted avg     0.7050    0.6975    0.6988       400\n",
      "\n",
      "[[95 14 18  0]\n",
      " [10 79 10  3]\n",
      " [12  8 62 31]\n",
      " [ 0  0 15 43]]\n",
      "66 4.641588833612782 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8136    0.7559    0.7837       127\n",
      "         1.0     0.7822    0.7745    0.7783       102\n",
      "         2.0     0.5980    0.5398    0.5674       113\n",
      "         3.0     0.5570    0.7586    0.6423        58\n",
      "\n",
      "    accuracy                         0.7000       400\n",
      "   macro avg     0.6877    0.7072    0.6929       400\n",
      "weighted avg     0.7075    0.7000    0.7007       400\n",
      "\n",
      "[[96 14 17  0]\n",
      " [10 79 10  3]\n",
      " [12  8 61 32]\n",
      " [ 0  0 14 44]]\n",
      "67 5.09413801481638 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8083    0.7638    0.7854       127\n",
      "         1.0     0.7767    0.7843    0.7805       102\n",
      "         2.0     0.6061    0.5310    0.5660       113\n",
      "         3.0     0.5513    0.7414    0.6324        58\n",
      "\n",
      "    accuracy                         0.7000       400\n",
      "   macro avg     0.6856    0.7051    0.6911       400\n",
      "weighted avg     0.7059    0.7000    0.7000       400\n",
      "\n",
      "[[97 15 15  0]\n",
      " [10 80  9  3]\n",
      " [13  8 60 32]\n",
      " [ 0  0 15 43]]\n",
      "68 5.590810182512229 0.705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8167    0.7717    0.7935       127\n",
      "         1.0     0.7921    0.7843    0.7882       102\n",
      "         2.0     0.6040    0.5398    0.5701       113\n",
      "         3.0     0.5513    0.7414    0.6324        58\n",
      "\n",
      "    accuracy                         0.7050       400\n",
      "   macro avg     0.6910    0.7093    0.6960       400\n",
      "weighted avg     0.7118    0.7050    0.7057       400\n",
      "\n",
      "[[98 13 16  0]\n",
      " [10 80  9  3]\n",
      " [12  8 61 32]\n",
      " [ 0  0 15 43]]\n",
      "69 6.135907273413176 0.7025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8151    0.7638    0.7886       127\n",
      "         1.0     0.7921    0.7843    0.7882       102\n",
      "         2.0     0.5980    0.5398    0.5674       113\n",
      "         3.0     0.5513    0.7414    0.6324        58\n",
      "\n",
      "    accuracy                         0.7025       400\n",
      "   macro avg     0.6891    0.7073    0.6941       400\n",
      "weighted avg     0.7097    0.7025    0.7034       400\n",
      "\n",
      "[[97 13 17  0]\n",
      " [10 80  9  3]\n",
      " [12  8 61 32]\n",
      " [ 0  0 15 43]]\n",
      "70 6.7341506577508286 0.6975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8120    0.7480    0.7787       127\n",
      "         1.0     0.7767    0.7843    0.7805       102\n",
      "         2.0     0.5980    0.5398    0.5674       113\n",
      "         3.0     0.5513    0.7414    0.6324        58\n",
      "\n",
      "    accuracy                         0.6975       400\n",
      "   macro avg     0.6845    0.7034    0.6897       400\n",
      "weighted avg     0.7047    0.6975    0.6983       400\n",
      "\n",
      "[[95 15 17  0]\n",
      " [10 80  9  3]\n",
      " [12  8 61 32]\n",
      " [ 0  0 15 43]]\n",
      "71 7.390722033525782 0.695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8051    0.7480    0.7755       127\n",
      "         1.0     0.7745    0.7745    0.7745       102\n",
      "         2.0     0.5962    0.5487    0.5714       113\n",
      "         3.0     0.5526    0.7241    0.6269        58\n",
      "\n",
      "    accuracy                         0.6950       400\n",
      "   macro avg     0.6821    0.6988    0.6871       400\n",
      "weighted avg     0.7017    0.6950    0.6960       400\n",
      "\n",
      "[[95 15 17  0]\n",
      " [11 79  9  3]\n",
      " [12  8 62 31]\n",
      " [ 0  0 16 42]]\n",
      "72 8.111308307896872 0.695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8051    0.7480    0.7755       127\n",
      "         1.0     0.7745    0.7745    0.7745       102\n",
      "         2.0     0.5962    0.5487    0.5714       113\n",
      "         3.0     0.5526    0.7241    0.6269        58\n",
      "\n",
      "    accuracy                         0.6950       400\n",
      "   macro avg     0.6821    0.6988    0.6871       400\n",
      "weighted avg     0.7017    0.6950    0.6960       400\n",
      "\n",
      "[[95 15 17  0]\n",
      " [11 79  9  3]\n",
      " [12  8 62 31]\n",
      " [ 0  0 16 42]]\n",
      "73 8.902150854450392 0.6925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8051    0.7480    0.7755       127\n",
      "         1.0     0.7700    0.7549    0.7624       102\n",
      "         2.0     0.5888    0.5575    0.5727       113\n",
      "         3.0     0.5600    0.7241    0.6316        58\n",
      "\n",
      "    accuracy                         0.6925       400\n",
      "   macro avg     0.6810    0.6961    0.6855       400\n",
      "weighted avg     0.6995    0.6925    0.6940       400\n",
      "\n",
      "[[95 15 17  0]\n",
      " [11 77 11  3]\n",
      " [12  8 63 30]\n",
      " [ 0  0 16 42]]\n",
      "74 9.770099572992256 0.6925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8051    0.7480    0.7755       127\n",
      "         1.0     0.7700    0.7549    0.7624       102\n",
      "         2.0     0.5888    0.5575    0.5727       113\n",
      "         3.0     0.5600    0.7241    0.6316        58\n",
      "\n",
      "    accuracy                         0.6925       400\n",
      "   macro avg     0.6810    0.6961    0.6855       400\n",
      "weighted avg     0.6995    0.6925    0.6940       400\n",
      "\n",
      "[[95 15 17  0]\n",
      " [11 77 11  3]\n",
      " [12  8 63 30]\n",
      " [ 0  0 16 42]]\n",
      "75 10.722672220103243 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7917    0.7480    0.7692       127\n",
      "         1.0     0.7700    0.7549    0.7624       102\n",
      "         2.0     0.5905    0.5487    0.5688       113\n",
      "         3.0     0.5600    0.7241    0.6316        58\n",
      "\n",
      "    accuracy                         0.6900       400\n",
      "   macro avg     0.6780    0.6939    0.6830       400\n",
      "weighted avg     0.6957    0.6900    0.6909       400\n",
      "\n",
      "[[95 15 17  0]\n",
      " [13 77 10  2]\n",
      " [12  8 62 31]\n",
      " [ 0  0 16 42]]\n",
      "76 11.768119524349991 0.6875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7851    0.7480    0.7661       127\n",
      "         1.0     0.7677    0.7451    0.7562       102\n",
      "         2.0     0.5905    0.5487    0.5688       113\n",
      "         3.0     0.5600    0.7241    0.6316        58\n",
      "\n",
      "    accuracy                         0.6875       400\n",
      "   macro avg     0.6758    0.6915    0.6807       400\n",
      "weighted avg     0.6930    0.6875    0.6883       400\n",
      "\n",
      "[[95 15 17  0]\n",
      " [14 76 10  2]\n",
      " [12  8 62 31]\n",
      " [ 0  0 16 42]]\n",
      "77 12.91549665014884 0.6875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7851    0.7480    0.7661       127\n",
      "         1.0     0.7677    0.7451    0.7562       102\n",
      "         2.0     0.5905    0.5487    0.5688       113\n",
      "         3.0     0.5600    0.7241    0.6316        58\n",
      "\n",
      "    accuracy                         0.6875       400\n",
      "   macro avg     0.6758    0.6915    0.6807       400\n",
      "weighted avg     0.6930    0.6875    0.6883       400\n",
      "\n",
      "[[95 15 17  0]\n",
      " [14 76 10  2]\n",
      " [12  8 62 31]\n",
      " [ 0  0 16 42]]\n",
      "78 14.174741629268063 0.6875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7760    0.7638    0.7698       127\n",
      "         1.0     0.7708    0.7255    0.7475       102\n",
      "         2.0     0.5962    0.5487    0.5714       113\n",
      "         3.0     0.5600    0.7241    0.6316        58\n",
      "\n",
      "    accuracy                         0.6875       400\n",
      "   macro avg     0.6757    0.6905    0.6801       400\n",
      "weighted avg     0.6926    0.6875    0.6880       400\n",
      "\n",
      "[[97 14 16  0]\n",
      " [16 74 10  2]\n",
      " [12  8 62 31]\n",
      " [ 0  0 16 42]]\n",
      "79 15.556761439304722 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7778    0.7717    0.7747       127\n",
      "         1.0     0.7789    0.7255    0.7513       102\n",
      "         2.0     0.5962    0.5487    0.5714       113\n",
      "         3.0     0.5600    0.7241    0.6316        58\n",
      "\n",
      "    accuracy                         0.6900       400\n",
      "   macro avg     0.6782    0.6925    0.6822       400\n",
      "weighted avg     0.6952    0.6900    0.6905       400\n",
      "\n",
      "[[98 13 16  0]\n",
      " [16 74 10  2]\n",
      " [12  8 62 31]\n",
      " [ 0  0 16 42]]\n",
      "80 17.07352647470692 0.6725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7519    0.7638    0.7578       127\n",
      "         1.0     0.7684    0.7157    0.7411       102\n",
      "         2.0     0.5800    0.5133    0.5446       113\n",
      "         3.0     0.5395    0.7069    0.6119        58\n",
      "\n",
      "    accuracy                         0.6725       400\n",
      "   macro avg     0.6600    0.6749    0.6639       400\n",
      "weighted avg     0.6768    0.6725    0.6722       400\n",
      "\n",
      "[[97 14 16  0]\n",
      " [18 73  9  2]\n",
      " [14  8 58 33]\n",
      " [ 0  0 17 41]]\n",
      "81 18.73817422860385 0.6675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7442    0.7559    0.7500       127\n",
      "         1.0     0.7579    0.7059    0.7310       102\n",
      "         2.0     0.5728    0.5221    0.5463       113\n",
      "         3.0     0.5479    0.6897    0.6107        58\n",
      "\n",
      "    accuracy                         0.6675       400\n",
      "   macro avg     0.6557    0.6684    0.6595       400\n",
      "weighted avg     0.6708    0.6675    0.6674       400\n",
      "\n",
      "[[96 13 18  0]\n",
      " [19 72  9  2]\n",
      " [13 10 59 31]\n",
      " [ 1  0 17 40]]\n",
      "82 20.565123083486537 0.6775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7194    0.7874    0.7519       127\n",
      "         1.0     0.7609    0.6863    0.7216       102\n",
      "         2.0     0.6250    0.5310    0.5742       113\n",
      "         3.0     0.5616    0.7069    0.6260        58\n",
      "\n",
      "    accuracy                         0.6775       400\n",
      "   macro avg     0.6667    0.6779    0.6684       400\n",
      "weighted avg     0.6804    0.6775    0.6757       400\n",
      "\n",
      "[[100  12  15   0]\n",
      " [ 22  70   9   1]\n",
      " [ 14   8  60  31]\n",
      " [  3   2  12  41]]\n",
      "83 22.570197196339215 0.665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6846    0.8031    0.7391       127\n",
      "         1.0     0.7356    0.6275    0.6772       102\n",
      "         2.0     0.6517    0.5133    0.5743       113\n",
      "         3.0     0.5600    0.7241    0.6316        58\n",
      "\n",
      "    accuracy                         0.6650       400\n",
      "   macro avg     0.6580    0.6670    0.6556       400\n",
      "weighted avg     0.6702    0.6650    0.6612       400\n",
      "\n",
      "[[102  12  11   2]\n",
      " [ 27  64   9   2]\n",
      " [ 17   9  58  29]\n",
      " [  3   2  11  42]]\n",
      "84 24.770763559917114 0.6775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6750    0.8504    0.7526       127\n",
      "         1.0     0.7927    0.6373    0.7065       102\n",
      "         2.0     0.6552    0.5044    0.5700       113\n",
      "         3.0     0.5775    0.7069    0.6357        58\n",
      "\n",
      "    accuracy                         0.6775       400\n",
      "   macro avg     0.6751    0.6747    0.6662       400\n",
      "weighted avg     0.6853    0.6775    0.6723       400\n",
      "\n",
      "[[108   9   8   2]\n",
      " [ 27  65   8   2]\n",
      " [ 22   8  57  26]\n",
      " [  3   0  14  41]]\n",
      "85 27.185882427329428 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6215    0.8661    0.7237       127\n",
      "         1.0     0.7973    0.5784    0.6705       102\n",
      "         2.0     0.6420    0.4602    0.5361       113\n",
      "         3.0     0.6029    0.7069    0.6508        58\n",
      "\n",
      "    accuracy                         0.6550       400\n",
      "   macro avg     0.6659    0.6529    0.6453       400\n",
      "weighted avg     0.6694    0.6550    0.6465       400\n",
      "\n",
      "[[110   7   9   1]\n",
      " [ 34  59   6   3]\n",
      " [ 30   8  52  23]\n",
      " [  3   0  14  41]]\n",
      "86 29.836472402833405 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5907    0.8976    0.7125       127\n",
      "         1.0     0.8594    0.5392    0.6627       102\n",
      "         2.0     0.6707    0.4867    0.5641       113\n",
      "         3.0     0.6557    0.6897    0.6723        58\n",
      "\n",
      "    accuracy                         0.6600       400\n",
      "   macro avg     0.6941    0.6533    0.6529       400\n",
      "weighted avg     0.6912    0.6600    0.6520       400\n",
      "\n",
      "[[114   3   8   2]\n",
      " [ 40  55   5   2]\n",
      " [ 35   6  55  17]\n",
      " [  4   0  14  40]]\n",
      "87 32.745491628777316 0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5273    0.9134    0.6686       127\n",
      "         1.0     0.9107    0.5000    0.6456       102\n",
      "         2.0     0.7213    0.3894    0.5057       113\n",
      "         3.0     0.6190    0.6724    0.6446        58\n",
      "\n",
      "    accuracy                         0.6250       400\n",
      "   macro avg     0.6946    0.6188    0.6161       400\n",
      "weighted avg     0.6932    0.6250    0.6132       400\n",
      "\n",
      "[[116   2   6   3]\n",
      " [ 46  51   2   3]\n",
      " [ 50   1  44  18]\n",
      " [  8   2   9  39]]\n",
      "88 35.938136638046295 0.595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5000    0.9370    0.6521       127\n",
      "         1.0     0.9273    0.5000    0.6497       102\n",
      "         2.0     0.6346    0.2920    0.4000       113\n",
      "         3.0     0.6364    0.6034    0.6195        58\n",
      "\n",
      "    accuracy                         0.5950       400\n",
      "   macro avg     0.6746    0.5831    0.5803       400\n",
      "weighted avg     0.6668    0.5950    0.5755       400\n",
      "\n",
      "[[119   3   5   0]\n",
      " [ 48  51   0   3]\n",
      " [ 62   1  33  17]\n",
      " [  9   0  14  35]]\n",
      "89 39.4420605943766 0.575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4672    0.9528    0.6269       127\n",
      "         1.0     0.9200    0.4510    0.6053       102\n",
      "         2.0     0.6757    0.2212    0.3333       113\n",
      "         3.0     0.7037    0.6552    0.6786        58\n",
      "\n",
      "    accuracy                         0.5750       400\n",
      "   macro avg     0.6916    0.5700    0.5610       400\n",
      "weighted avg     0.6758    0.5750    0.5460       400\n",
      "\n",
      "[[121   2   3   1]\n",
      " [ 54  46   1   1]\n",
      " [ 72   2  25  14]\n",
      " [ 12   0   8  38]]\n",
      "90 43.287612810830616 0.545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4485    0.9606    0.6115       127\n",
      "         1.0     0.9216    0.4608    0.6144       102\n",
      "         2.0     0.5455    0.1593    0.2466       113\n",
      "         3.0     0.7045    0.5345    0.6078        58\n",
      "\n",
      "    accuracy                         0.5450       400\n",
      "   macro avg     0.6550    0.5288    0.5201       400\n",
      "weighted avg     0.6337    0.5450    0.5086       400\n",
      "\n",
      "[[122   3   2   0]\n",
      " [ 55  47   0   0]\n",
      " [ 81   1  18  13]\n",
      " [ 14   0  13  31]]\n",
      "91 47.50810162102798 0.54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4351    0.9764    0.6019       127\n",
      "         1.0     0.9388    0.4510    0.6093       102\n",
      "         2.0     0.5833    0.1239    0.2044       113\n",
      "         3.0     0.7619    0.5517    0.6400        58\n",
      "\n",
      "    accuracy                         0.5400       400\n",
      "   macro avg     0.6798    0.5257    0.5139       400\n",
      "weighted avg     0.6528    0.5400    0.4970       400\n",
      "\n",
      "[[124   2   1   0]\n",
      " [ 55  46   1   0]\n",
      " [ 88   1  14  10]\n",
      " [ 18   0   8  32]]\n",
      "92 52.140082879996896 0.5275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4218    0.9764    0.5891       127\n",
      "         1.0     0.9375    0.4412    0.6000       102\n",
      "         2.0     0.5294    0.0796    0.1385       113\n",
      "         3.0     0.8049    0.5690    0.6667        58\n",
      "\n",
      "    accuracy                         0.5275       400\n",
      "   macro avg     0.6734    0.5165    0.4986       400\n",
      "weighted avg     0.6392    0.5275    0.4758       400\n",
      "\n",
      "[[124   2   1   0]\n",
      " [ 56  45   1   0]\n",
      " [ 95   1   9   8]\n",
      " [ 19   0   6  33]]\n",
      "93 57.223676593502205 0.5075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4072    0.9843    0.5760       127\n",
      "         1.0     0.9302    0.3922    0.5517       102\n",
      "         2.0     0.5000    0.0442    0.0813       113\n",
      "         3.0     0.8250    0.5690    0.6735        58\n",
      "\n",
      "    accuracy                         0.5075       400\n",
      "   macro avg     0.6656    0.4974    0.4706       400\n",
      "weighted avg     0.6274    0.5075    0.4442       400\n",
      "\n",
      "[[125   1   1   0]\n",
      " [ 62  40   0   0]\n",
      " [100   1   5   7]\n",
      " [ 20   1   4  33]]\n",
      "94 62.802914418342596 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4019    0.9843    0.5708       127\n",
      "         1.0     0.9524    0.3922    0.5556       102\n",
      "         2.0     0.4444    0.0354    0.0656       113\n",
      "         3.0     0.8158    0.5345    0.6458        58\n",
      "\n",
      "    accuracy                         0.5000       400\n",
      "   macro avg     0.6536    0.4866    0.4594       400\n",
      "weighted avg     0.6143    0.5000    0.4351       400\n",
      "\n",
      "[[125   1   1   0]\n",
      " [ 62  40   0   0]\n",
      " [101   1   4   7]\n",
      " [ 23   0   4  31]]\n",
      "95 68.92612104349702 0.4925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3981    0.9843    0.5669       127\n",
      "         1.0     0.9512    0.3824    0.5455       102\n",
      "         2.0     0.4000    0.0354    0.0650       113\n",
      "         3.0     0.8286    0.5000    0.6237        58\n",
      "\n",
      "    accuracy                         0.4925       400\n",
      "   macro avg     0.6445    0.4755    0.4503       400\n",
      "weighted avg     0.6021    0.4925    0.4279       400\n",
      "\n",
      "[[125   1   1   0]\n",
      " [ 63  39   0   0]\n",
      " [102   1   4   6]\n",
      " [ 24   0   5  29]]\n",
      "96 75.64633275546291 0.4825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3937    0.9921    0.5638       127\n",
      "         1.0     0.9474    0.3529    0.5143       102\n",
      "         2.0     0.4444    0.0354    0.0656       113\n",
      "         3.0     0.8182    0.4655    0.5934        58\n",
      "\n",
      "    accuracy                         0.4825       400\n",
      "   macro avg     0.6509    0.4615    0.4343       400\n",
      "weighted avg     0.6108    0.4825    0.4147       400\n",
      "\n",
      "[[126   1   0   0]\n",
      " [ 66  36   0   0]\n",
      " [102   1   4   6]\n",
      " [ 26   0   5  27]]\n",
      "97 83.02175681319753 0.4725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3853    0.9921    0.5551       127\n",
      "         1.0     0.9474    0.3529    0.5143       102\n",
      "         2.0     0.5000    0.0265    0.0504       113\n",
      "         3.0     0.8276    0.4138    0.5517        58\n",
      "\n",
      "    accuracy                         0.4725       400\n",
      "   macro avg     0.6651    0.4464    0.4179       400\n",
      "weighted avg     0.6252    0.4725    0.4016       400\n",
      "\n",
      "[[126   1   0   0]\n",
      " [ 66  36   0   0]\n",
      " [104   1   3   5]\n",
      " [ 31   0   3  24]]\n",
      "98 91.11627561154896 0.47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3837    1.0000    0.5546       127\n",
      "         1.0     0.9722    0.3431    0.5072       102\n",
      "         2.0     0.5000    0.0177    0.0342       113\n",
      "         3.0     0.8276    0.4138    0.5517        58\n",
      "\n",
      "    accuracy                         0.4700       400\n",
      "   macro avg     0.6709    0.4437    0.4119       400\n",
      "weighted avg     0.6310    0.4700    0.3951       400\n",
      "\n",
      "[[127   0   0   0]\n",
      " [ 67  35   0   0]\n",
      " [105   1   2   5]\n",
      " [ 32   0   2  24]]\n",
      "99 100.0 0.4625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3802    1.0000    0.5510       127\n",
      "         1.0     0.9722    0.3431    0.5072       102\n",
      "         2.0     0.5000    0.0177    0.0342       113\n",
      "         3.0     0.8077    0.3621    0.5000        58\n",
      "\n",
      "    accuracy                         0.4625       400\n",
      "   macro avg     0.6650    0.4307    0.3981       400\n",
      "weighted avg     0.6270    0.4625    0.3864       400\n",
      "\n",
      "[[127   0   0   0]\n",
      " [ 67  35   0   0]\n",
      " [105   1   2   5]\n",
      " [ 35   0   2  21]]\n"
     ]
    }
   ],
   "source": [
    "# 加了个循环\n",
    "data = np.loadtxt(open(\"w2v_cleaned_mean_shuffle_5000.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
    "X = data[:, : -1]  # 输入\n",
    "y = data[:, -1]  # 标签\n",
    "rng = np.random.RandomState(5)  # 随机数种子\n",
    "indices = np.arange(len(data))\n",
    "rng.shuffle(indices)  # 将索引打乱\n",
    "train_indices = indices[400:]\n",
    "test_indices = indices[:400]\n",
    "\n",
    "initial_labeled_points = 300\n",
    "unlabeled_indices = train_indices[initial_labeled_points:]\n",
    "X_train = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "y_train[initial_labeled_points:] = -1\n",
    "\n",
    "num=100\n",
    "gammas = np.logspace(-2, 2, num=num)\n",
    "np.seterr(divide='ignore',invalid='ignore')\n",
    "for i in range(num):\n",
    "    lp_model = LabelSpreading(gamma=gammas[i], max_iter=30)\n",
    "    lp_model.fit(X_train, y_train)\n",
    "    pred_entropies = stats.distributions.entropy(lp_model.label_distributions_.T)\n",
    "    # print(pred_entropies,len(pred_entropies))\n",
    "    # 选择分类器最不确定的最多5位数字示例\n",
    "    uncertainty_index = np.argsort(pred_entropies)[::-1]\n",
    "    # print(uncertainty_index,len(uncertainty_index))\n",
    "    uncertainty_index = uncertainty_index[\n",
    "    np.in1d(uncertainty_index, train_indices)][:1300]\n",
    "\n",
    "\n",
    "    as_labeled_indices = np.concatenate((train_indices[:300], uncertainty_index),axis=0) # 挑选出的1600个样本作为传播的起点\n",
    "    new_index = np.concatenate((as_labeled_indices, test_indices),axis=0)# 总共的2000样本索引\n",
    "    new_x = X[new_index]\n",
    "    new_y = y[new_index]\n",
    "    new_y[1600:] = -1\n",
    "\n",
    "    lp_model.fit(new_x, new_y)\n",
    "    predicted_labels = lp_model.transduction_[1600:]\n",
    "    true_labels = y[test_indices]\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels,\n",
    "                              labels=lp_model.classes_)\n",
    "    SC = accuracy_score(true_labels, predicted_labels)\n",
    "    print(i,gammas[i],SC)\n",
    "    print(classification_report(true_labels, predicted_labels, digits=4))\n",
    "    # print(\"Confusion matrix\")\n",
    "    print(cm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}