{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15454428  0.52875054 -0.47713432  0.26700583  0.5780986  -0.2584704\n",
      " -0.497395   -0.37840477 -0.04801681 -0.1354587  -0.30140558  0.3864191\n",
      "  0.10743058 -0.16617118 -0.04376784  0.19094634 -0.662355   -0.09070095\n",
      " -0.23156993 -0.5459718  -0.10523433 -0.20469089  0.09074577 -0.08418999\n",
      " -0.6287511  -0.4343539  -0.17811942 -0.26209912  0.59038424 -0.03774031\n",
      " -0.14668883  0.30349293  0.03785542 -0.2719773  -0.32126015 -0.06889755\n",
      "  0.03629145  0.33375648  0.01039888 -0.12757844  0.16452992 -0.07805916\n",
      "  0.6332627  -0.00853407  0.5796044  -0.4813189  -0.415879   -0.18914485\n",
      "  0.37880462 -0.535376    0.27505007 -0.0053158   0.43196863 -0.10982956\n",
      " -0.2483539   0.57755494  1.2750691  -0.2753227   0.21096511  0.17983645\n",
      "  0.07333843  0.32510185  0.21086293  0.35948765 -1.0670815  -0.24465425\n",
      " -0.05507161  0.22329137  0.18268651  0.23923065 -0.15428372  0.45899114\n",
      " -0.07298146 -0.14948614  0.28234842  0.2845556   0.48830715  0.0445042\n",
      "  0.2580861   0.5829236  -0.24267407 -0.1792513   0.06444535 -0.57681924\n",
      " -0.37758455 -0.48768583 -0.2026768  -0.13064437  0.0023602   0.08080367\n",
      "  0.35680678 -0.00684096 -0.21969618  0.02405959  0.20493968  0.24756914\n",
      "  0.3250612  -0.05901336 -0.573305   -0.32730082] \n",
      " 100\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½é¢„è®­ç»ƒç‰¹å¾æå–æ¨¡å‹\n",
    "# reference website: https://wikipedia2vec.github.io/wikipedia2vec/usage/#api-usage\n",
    "import numpy as np\n",
    "from wikipedia2vec import Wikipedia2Vec\n",
    "# å¿…é¡»ä¸‹è½½äºŒè¿›åˆ¶æ–‡ä»¶å¦åˆ™ä¸‹ä¸€æ­¥ä¼šæŠ¥é”™ï¼Œæµªè´¹æˆ‘ä¸€ä¸ªå°æ—¶ï¼Œæ€’ğŸ˜¡\n",
    "wiki2vec = Wikipedia2Vec.load('zhwiki_20180420_100d.pkl')\n",
    "# test\n",
    "vec = wiki2vec.get_word_vector('æˆ‘')\n",
    "vectorsize = vec.size\n",
    "print(vec,'\\n',vectorsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®æ€»é‡: 2000 .\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                         text  label\n325                        è°¢è°¢ï¼Œæ˜¯æˆ‘å­¤é™‹å¯¡é—»ï¼Œæ´›å¿…è¾¾æ³•åˆ™æ²¡ç”¨è¿‡      0\n1375  å‡½æ•°çš„æ±‚å¯¼æ³•åˆ™è¯·è€å¸ˆå†™ä¸‹å›¾ç‰‡ä¸­çº¢æ¡†éƒ¨åˆ†çš„æ¼”ç®—æ­¥éª¤ï¼Œä»¥åŠä¸‹è¾¹è“è‰²åˆ’çº¿éƒ¨åˆ†æ€ä¹ˆæ¥çš„      2\n1692                                    æ±‚è€å¸ˆè§£ç­”      3\n298                      xâ†’âˆï¼Œæ˜¯xè¶‹å‘äºæ­£æ— ç©·ï¼Œè¿˜æ˜¯è¶‹å‘äºæ— ç©·      0\n1171                                è¯·é—®ç¬¬äºŒé¢˜æ€ä¹ˆåšå•Š      2\n1440                                   dyä»£è¡¨ä»€ä¹ˆ      2\n1283                               è€å¸ˆï¼Œä¸ºä»€ä¹ˆæé™ä¸ºå•Š      2\n1621                                      å“ªä¸¤ä¸ª      3\n1735                                èƒ½ä¸èƒ½å†™ä¸€ä¸‹å¼å­é¸­      3\n1699                             è€å¸ˆè¯·é—®è¿™é¢˜è¯¥æ€ä¹ˆè§£è°¢è°¢      3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>325</th>\n      <td>è°¢è°¢ï¼Œæ˜¯æˆ‘å­¤é™‹å¯¡é—»ï¼Œæ´›å¿…è¾¾æ³•åˆ™æ²¡ç”¨è¿‡</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1375</th>\n      <td>å‡½æ•°çš„æ±‚å¯¼æ³•åˆ™è¯·è€å¸ˆå†™ä¸‹å›¾ç‰‡ä¸­çº¢æ¡†éƒ¨åˆ†çš„æ¼”ç®—æ­¥éª¤ï¼Œä»¥åŠä¸‹è¾¹è“è‰²åˆ’çº¿éƒ¨åˆ†æ€ä¹ˆæ¥çš„</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1692</th>\n      <td>æ±‚è€å¸ˆè§£ç­”</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>xâ†’âˆï¼Œæ˜¯xè¶‹å‘äºæ­£æ— ç©·ï¼Œè¿˜æ˜¯è¶‹å‘äºæ— ç©·</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1171</th>\n      <td>è¯·é—®ç¬¬äºŒé¢˜æ€ä¹ˆåšå•Š</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1440</th>\n      <td>dyä»£è¡¨ä»€ä¹ˆ</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1283</th>\n      <td>è€å¸ˆï¼Œä¸ºä»€ä¹ˆæé™ä¸ºå•Š</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1621</th>\n      <td>å“ªä¸¤ä¸ª</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1735</th>\n      <td>èƒ½ä¸èƒ½å†™ä¸€ä¸‹å¼å­é¸­</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1699</th>\n      <td>è€å¸ˆè¯·é—®è¿™é¢˜è¯¥æ€ä¹ˆè§£è°¢è°¢</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#å®šä¹‰åˆ é™¤é™¤å­—æ¯,æ•°å­—ï¼Œæ±‰å­—ä»¥å¤–çš„æ‰€æœ‰ç¬¦å·çš„å‡½æ•°\n",
    "def remove_punctuation(line):\n",
    "    line = str(line)\n",
    "    if line.strip()=='':\n",
    "        return ''\n",
    "    rule = re.compile(u\"[^a-zA-Z0-9\\u4E00-\\u9FA5]\")\n",
    "    line = rule.sub('',line)\n",
    "    return line\n",
    "\n",
    "#åœç”¨è¯åˆ—è¡¨\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "#åŠ è½½åœç”¨è¯\n",
    "stopwords = stopwordslist(\"./stopwords.txt\")\n",
    "\n",
    "import pandas as pd\n",
    "# df = pd.read_csv('./data_lite_all.csv')\n",
    "df = pd.read_csv('./data_cleaned_1.csv')\n",
    "df=df[['text','label']]\n",
    "print(\"æ•°æ®æ€»é‡: %d .\" % len(df))\n",
    "df.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\WINDOWS\\TEMP\\jieba.cache\n",
      "Loading model cost 0.489 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                            text  label  \\\n0                                 ä¸ºä»€ä¹ˆæ— ç•Œå‡½æ•°ä¸ä¸€å®šä¸ºæ— ç©·å¤§      0   \n1  åˆ¤æ–­ï¼Œå¤„æœ‰æ— å®šä¹‰ï¼Œè‹¥ï¼Œå¤„æœ‰å®šä¹‰ï¼Œä½†æ˜¯ï¼Œä¸å­˜åœ¨ï¼Œå³ï¼Œä¸å­˜åœ¨æˆ–ï¼Œä¸å­˜åœ¨ï¼Œè‹¥ï¼Œå¤„æœ‰å®šä¹‰å­˜åœ¨ï¼Œä½†æ˜¯      0   \n2                                             è°¢è°¢      0   \n3                                     å…ˆå¼€ä¸Šé¢ä¸‰æ¬¡æ–¹å†æ±‚å¯¼      0   \n4  æ±‚è§£ç­”è¿™é‡Œæ˜¯è®²æ”¶æ•›æ•°åˆ—çš„æœ‰ç•Œæ€§ï¼Œä¸ºä»€ä¹ˆä¸¾ä¾‹æ˜¯è¿™ä¸ªä¾‹å­è¿™ä¸ªæ•°åˆ—å¹¶ä¸æ”¶æ•›å‘€è¿™ä¸ªæ•°åˆ—ä¸æ˜¯å‘æ•£çš„å—      0   \n\n                                     clean_text  \\\n0                                ä¸ºä»€ä¹ˆæ— ç•Œå‡½æ•°ä¸ä¸€å®šä¸ºæ— ç©·å¤§   \n1            åˆ¤æ–­å¤„æœ‰æ— å®šä¹‰è‹¥å¤„æœ‰å®šä¹‰ä½†æ˜¯ä¸å­˜åœ¨å³ä¸å­˜åœ¨æˆ–ä¸å­˜åœ¨è‹¥å¤„æœ‰å®šä¹‰å­˜åœ¨ä½†æ˜¯   \n2                                            è°¢è°¢   \n3                                    å…ˆå¼€ä¸Šé¢ä¸‰æ¬¡æ–¹å†æ±‚å¯¼   \n4  æ±‚è§£ç­”è¿™é‡Œæ˜¯è®²æ”¶æ•›æ•°åˆ—çš„æœ‰ç•Œæ€§ä¸ºä»€ä¹ˆä¸¾ä¾‹æ˜¯è¿™ä¸ªä¾‹å­è¿™ä¸ªæ•°åˆ—å¹¶ä¸æ”¶æ•›å‘€è¿™ä¸ªæ•°åˆ—ä¸æ˜¯å‘æ•£çš„å—   \n\n                                            cut_text  \n0                     [ä¸ºä»€ä¹ˆ, æ— , ç•Œ, å‡½æ•°, ä¸, ä¸€å®š, ä¸º, æ— ç©·å¤§]  \n1  [åˆ¤æ–­, å¤„, æœ‰æ— , å®šä¹‰, è‹¥å¤„, æœ‰, å®šä¹‰, ä½†æ˜¯, ä¸, å­˜åœ¨, å³, ä¸, å­˜åœ¨...  \n2                                               [è°¢è°¢]  \n3                               [å…ˆå¼€, ä¸Šé¢, ä¸‰æ¬¡æ–¹, å†, æ±‚å¯¼]  \n4  [æ±‚, è§£ç­”, è¿™é‡Œ, æ˜¯, è®², æ”¶æ•›, æ•°åˆ—, çš„, æœ‰ç•Œæ€§, ä¸ºä»€ä¹ˆ, ä¸¾ä¾‹, æ˜¯, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>clean_text</th>\n      <th>cut_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ä¸ºä»€ä¹ˆæ— ç•Œå‡½æ•°ä¸ä¸€å®šä¸ºæ— ç©·å¤§</td>\n      <td>0</td>\n      <td>ä¸ºä»€ä¹ˆæ— ç•Œå‡½æ•°ä¸ä¸€å®šä¸ºæ— ç©·å¤§</td>\n      <td>[ä¸ºä»€ä¹ˆ, æ— , ç•Œ, å‡½æ•°, ä¸, ä¸€å®š, ä¸º, æ— ç©·å¤§]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>åˆ¤æ–­ï¼Œå¤„æœ‰æ— å®šä¹‰ï¼Œè‹¥ï¼Œå¤„æœ‰å®šä¹‰ï¼Œä½†æ˜¯ï¼Œä¸å­˜åœ¨ï¼Œå³ï¼Œä¸å­˜åœ¨æˆ–ï¼Œä¸å­˜åœ¨ï¼Œè‹¥ï¼Œå¤„æœ‰å®šä¹‰å­˜åœ¨ï¼Œä½†æ˜¯</td>\n      <td>0</td>\n      <td>åˆ¤æ–­å¤„æœ‰æ— å®šä¹‰è‹¥å¤„æœ‰å®šä¹‰ä½†æ˜¯ä¸å­˜åœ¨å³ä¸å­˜åœ¨æˆ–ä¸å­˜åœ¨è‹¥å¤„æœ‰å®šä¹‰å­˜åœ¨ä½†æ˜¯</td>\n      <td>[åˆ¤æ–­, å¤„, æœ‰æ— , å®šä¹‰, è‹¥å¤„, æœ‰, å®šä¹‰, ä½†æ˜¯, ä¸, å­˜åœ¨, å³, ä¸, å­˜åœ¨...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>è°¢è°¢</td>\n      <td>0</td>\n      <td>è°¢è°¢</td>\n      <td>[è°¢è°¢]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>å…ˆå¼€ä¸Šé¢ä¸‰æ¬¡æ–¹å†æ±‚å¯¼</td>\n      <td>0</td>\n      <td>å…ˆå¼€ä¸Šé¢ä¸‰æ¬¡æ–¹å†æ±‚å¯¼</td>\n      <td>[å…ˆå¼€, ä¸Šé¢, ä¸‰æ¬¡æ–¹, å†, æ±‚å¯¼]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>æ±‚è§£ç­”è¿™é‡Œæ˜¯è®²æ”¶æ•›æ•°åˆ—çš„æœ‰ç•Œæ€§ï¼Œä¸ºä»€ä¹ˆä¸¾ä¾‹æ˜¯è¿™ä¸ªä¾‹å­è¿™ä¸ªæ•°åˆ—å¹¶ä¸æ”¶æ•›å‘€è¿™ä¸ªæ•°åˆ—ä¸æ˜¯å‘æ•£çš„å—</td>\n      <td>0</td>\n      <td>æ±‚è§£ç­”è¿™é‡Œæ˜¯è®²æ”¶æ•›æ•°åˆ—çš„æœ‰ç•Œæ€§ä¸ºä»€ä¹ˆä¸¾ä¾‹æ˜¯è¿™ä¸ªä¾‹å­è¿™ä¸ªæ•°åˆ—å¹¶ä¸æ”¶æ•›å‘€è¿™ä¸ªæ•°åˆ—ä¸æ˜¯å‘æ•£çš„å—</td>\n      <td>[æ±‚, è§£ç­”, è¿™é‡Œ, æ˜¯, è®², æ”¶æ•›, æ•°åˆ—, çš„, æœ‰ç•Œæ€§, ä¸ºä»€ä¹ˆ, ä¸¾ä¾‹, æ˜¯, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba as jb\n",
    "#åˆ é™¤é™¤å­—æ¯,æ•°å­—ï¼Œæ±‰å­—ä»¥å¤–çš„æ‰€æœ‰ç¬¦å·\n",
    "df['clean_text'] = df['text'].apply(remove_punctuation)\n",
    "\n",
    "#åˆ†è¯ï¼Œå¹¶è¿‡æ»¤åœç”¨è¯\n",
    "# df['cut_review'] = df['clean_review'].apply(lambda x: \" \".join([w for w in list(jb.cut(x)) if w not in stopwords]))\n",
    "df['cut_text'] = df['clean_text'].apply(lambda x: [w for w in list(jb.cut(x)) if w not in stopwords])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "79                                     ([è¿˜æœ‰, ç§, æ–¹æ³•], [0])\n344     ([å‡½æ•°, çš„, è¿ç»­æ€§, éº»çƒ¦, è€å¸ˆ, çœ‹ä¸‹ä¾‹, å’Œ, ä¾‹ä¸­, ç”»åœˆ, çš„, éƒ¨åˆ†, æ€...\n309            ([è€å¸ˆ, æ±‚è§£, ä¸‹é¢, å‡ ä¸ª, é¢˜ç›®, è¯·, è€å¸ˆ, è§£ç­”, ä¸€ä¸‹], [0])\n1973                             ([èƒ½, å¸®å¿™, è§£, ä¸€ä¸‹, å—], [3])\n1328                        ([è¯·é—®, è¿™ä¸ª, æé™, æ€ä¹ˆ, æ±‚, å•Š], [2])\n1869    ([æƒ³è¦, çŸ¥é“, è¯¦ç»†, çš„, è¿‡ç¨‹, å’Œ, æ¯, ä¸€æ­¥, çš„, ä¾æ®, å¦‚å›¾, å¸Œæœ›, ...\n1200                            ([è€å¸ˆ, è¿™é¢˜, æ€ä¹ˆ, åš, å•Š], [2])\n1565                                   ([è°, èƒ½, å¸®å¸®æˆ‘], [3])\n59                                      ([å•Š, æˆ‘ä¼š, äº†], [0])\n1758                              ([è€å¸ˆ, è¿™é“é¢˜, æ€ä¹ˆ, åš], [3])\ndtype: object"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "#åˆ›å»ºæ ‡ç­¾åŒ–æ–‡æ¡£\n",
    "train_tagged = df.apply(\n",
    "    lambda r: TaggedDocument(words=r['cut_text'], tags=[r['label']]), axis=1)\n",
    "train_tagged.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "('æ— ', [0], 0)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1=train_tagged[0][0]\n",
    "text2=train_tagged[0][1]\n",
    "text1[1],text2,text2[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([-0.2924,  0.1533, -0.1521,  0.4695,  0.1799,  0.1175, -0.1602, -0.7899,\n          0.7427, -0.0958,  0.0947,  0.2020, -0.4102, -0.1616,  0.1495, -0.2397,\n         -0.2724,  0.0600, -0.0103, -0.1817, -0.1020,  0.0334,  0.2580, -0.1205,\n         -0.5100, -0.3163, -0.0271, -0.1161,  0.2077, -0.1881,  0.2675,  0.2193,\n          0.5156,  0.3702, -0.0327, -0.1584,  0.3373, -0.1080, -0.0819, -0.1874,\n          0.1980,  0.1727,  0.3929, -0.3468,  0.5301, -0.4854, -0.5363, -0.2199,\n          0.1926, -0.6094,  0.0602,  0.6900,  0.4246,  0.4248,  0.2148, -0.0471,\n          0.8418, -0.2958,  0.3884,  0.5980,  0.3890,  0.3865, -0.3905, -0.1531,\n         -0.7449, -0.0657,  0.0027,  0.4643,  0.1590, -0.1030,  0.1285,  0.5606,\n          0.3592, -0.1796, -0.2919,  0.0113,  0.3375, -0.1267,  0.2550,  0.5555,\n         -0.1158, -0.1533, -0.0063, -0.5107, -0.0514, -0.2981, -0.2564,  0.0921,\n         -0.1424, -0.5418,  0.2905, -0.2002, -0.1603,  0.9346,  0.0510,  0.0556,\n          0.5027,  0.0431, -0.3708, -0.9284]),\n tensor([0., 0., 0.,  ..., 3., 3., 3.]))"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# åˆ†è¯åæŸ¥é˜…é¢„è®­ç»ƒæ¨¡å‹ä¸­æ¯ä¸ªå•è¯çš„ç‰¹å¾ï¼Œç„¶åå–å¹³å‡å€¼ï¼Œä¸ºé¿å…è¯å…¸ä¸­æ²¡æœ‰æŸä¸ªè¯è€Œå¯¼è‡´æŸ¥è¯¢æ—¶æ•´ä¸ªç¨‹åºåœæ­¢ï¼Œå¼•å…¥ç³»ç»Ÿä¸­\n",
    "# åˆå§‹åŒ–æ•°æ®\n",
    "data_length = 2000\n",
    "word_vector_size = 100\n",
    "label = torch.zeros(data_length)\n",
    "features = torch.zeros(data_length,word_vector_size)\n",
    "for i in range(len(train_tagged)):\n",
    "    cut_text = train_tagged[i][0]  # åˆ†è¯åæ–‡æœ¬\n",
    "    label[i] = train_tagged[i][1][0]  # æ ‡ç­¾å­˜å…¥label\n",
    "    # æ¯ä¸ªè¯çš„è¯å‘é‡\n",
    "    count = 0\n",
    "    for j in range(len(cut_text)):\n",
    "        try:\n",
    "            vec_temp = wiki2vec.get_word_vector(cut_text[j]) # è·å–å½“å‰è¯çš„è¯å‘é‡\n",
    "            features[i] += vec_temp\n",
    "            # print(vec_temp)\n",
    "            count += 1\n",
    "        except Exception as f:\n",
    "            # print(\"Exception f\")\n",
    "            ex = 1\n",
    "    if count!=0: features[i] /= count\n",
    "    # print(features[i])\n",
    "    # break\n",
    "features[1999],label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.01 0.3625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9231    0.2400    0.3810       100\n",
      "         1.0     0.7027    0.2549    0.3741       102\n",
      "         2.0     0.2819    0.9694    0.4368        98\n",
      "         3.0     0.0000    0.0000    0.0000       100\n",
      "\n",
      "    accuracy                         0.3625       400\n",
      "   macro avg     0.4769    0.3661    0.2980       400\n",
      "weighted avg     0.4790    0.3625    0.2976       400\n",
      "\n",
      "1 0.010974987654930561 0.3725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9259    0.2500    0.3937       100\n",
      "         1.0     0.6829    0.2745    0.3916       102\n",
      "         2.0     0.2857    0.9592    0.4403        98\n",
      "         3.0     0.6667    0.0200    0.0388       100\n",
      "\n",
      "    accuracy                         0.3725       400\n",
      "   macro avg     0.6403    0.3759    0.3161       400\n",
      "weighted avg     0.6423    0.3725    0.3159       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Software\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.012045035402587823 0.3875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9259    0.2500    0.3937       100\n",
      "         1.0     0.6939    0.3333    0.4503       102\n",
      "         2.0     0.2928    0.9592    0.4487        98\n",
      "         3.0     0.6667    0.0200    0.0388       100\n",
      "\n",
      "    accuracy                         0.3875       400\n",
      "   macro avg     0.6448    0.3906    0.3329       400\n",
      "weighted avg     0.6468    0.3875    0.3329       400\n",
      "\n",
      "3 0.013219411484660288 0.395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9286    0.2600    0.4062       100\n",
      "         1.0     0.6981    0.3627    0.4774       102\n",
      "         2.0     0.2943    0.9490    0.4493        98\n",
      "         3.0     0.6667    0.0200    0.0388       100\n",
      "\n",
      "    accuracy                         0.3950       400\n",
      "   macro avg     0.6469    0.3979    0.3429       400\n",
      "weighted avg     0.6489    0.3950    0.3431       400\n",
      "\n",
      "4 0.014508287784959394 0.4025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9310    0.2700    0.4186       100\n",
      "         1.0     0.6964    0.3824    0.4937       102\n",
      "         2.0     0.2981    0.9490    0.4537        98\n",
      "         3.0     0.6667    0.0200    0.0388       100\n",
      "\n",
      "    accuracy                         0.4025       400\n",
      "   macro avg     0.6481    0.4053    0.3512       400\n",
      "weighted avg     0.6500    0.4025    0.3514       400\n",
      "\n",
      "5 0.015922827933410922 0.415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9355    0.2900    0.4427       100\n",
      "         1.0     0.7119    0.4118    0.5217       102\n",
      "         2.0     0.3029    0.9490    0.4593        98\n",
      "         3.0     0.6667    0.0200    0.0388       100\n",
      "\n",
      "    accuracy                         0.4150       400\n",
      "   macro avg     0.6542    0.4177    0.3656       400\n",
      "weighted avg     0.6563    0.4150    0.3660       400\n",
      "\n",
      "6 0.01747528400007684 0.4275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9375    0.3000    0.4545       100\n",
      "         1.0     0.7302    0.4510    0.5576       102\n",
      "         2.0     0.3079    0.9490    0.4650        98\n",
      "         3.0     0.6667    0.0200    0.0388       100\n",
      "\n",
      "    accuracy                         0.4275       400\n",
      "   macro avg     0.6606    0.4300    0.3790       400\n",
      "weighted avg     0.6627    0.4275    0.3795       400\n",
      "\n",
      "7 0.019179102616724886 0.4475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9429    0.3300    0.4889       100\n",
      "         1.0     0.7286    0.5000    0.5930       102\n",
      "         2.0     0.3162    0.9388    0.4730        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4475       400\n",
      "   macro avg     0.6844    0.4497    0.4032       400\n",
      "weighted avg     0.6865    0.4475    0.4038       400\n",
      "\n",
      "8 0.02104904144512021 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9444    0.3400    0.5000       100\n",
      "         1.0     0.7237    0.5392    0.6180       102\n",
      "         2.0     0.3239    0.9388    0.4817        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4600       400\n",
      "   macro avg     0.6855    0.4620    0.4143       400\n",
      "weighted avg     0.6875    0.4600    0.4150       400\n",
      "\n",
      "9 0.023101297000831605 0.4675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9444    0.3400    0.5000       100\n",
      "         1.0     0.7073    0.5686    0.6304       102\n",
      "         2.0     0.3309    0.9388    0.4894        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4675       400\n",
      "   macro avg     0.6832    0.4694    0.4194       400\n",
      "weighted avg     0.6851    0.4675    0.4201       400\n",
      "\n",
      "10 0.025353644939701114 0.4725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9444    0.3400    0.5000       100\n",
      "         1.0     0.7059    0.5882    0.6417       102\n",
      "         2.0     0.3345    0.9388    0.4933        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4725       400\n",
      "   macro avg     0.6837    0.4743    0.4232       400\n",
      "weighted avg     0.6856    0.4725    0.4239       400\n",
      "\n",
      "11 0.027825594022071243 0.4825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9444    0.3400    0.5000       100\n",
      "         1.0     0.7111    0.6275    0.6667       102\n",
      "         2.0     0.3407    0.9388    0.5000        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4825       400\n",
      "   macro avg     0.6866    0.4841    0.4311       400\n",
      "weighted avg     0.6884    0.4825    0.4319       400\n",
      "\n",
      "12 0.030538555088334154 0.4875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9459    0.3500    0.5109       100\n",
      "         1.0     0.7143    0.6373    0.6736       102\n",
      "         2.0     0.3433    0.9388    0.5027        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4875       400\n",
      "   macro avg     0.6884    0.4890    0.4362       400\n",
      "weighted avg     0.6902    0.4875    0.4371       400\n",
      "\n",
      "13 0.033516026509388425 0.4875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9459    0.3500    0.5109       100\n",
      "         1.0     0.6989    0.6373    0.6667       102\n",
      "         2.0     0.3459    0.9388    0.5055        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4875       400\n",
      "   macro avg     0.6852    0.4890    0.4352       400\n",
      "weighted avg     0.6869    0.4875    0.4360       400\n",
      "\n",
      "14 0.03678379771828634 0.4925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6804    0.6471    0.6633       102\n",
      "         2.0     0.3500    0.9286    0.5084        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4925       400\n",
      "   macro avg     0.6823    0.4939    0.4404       400\n",
      "weighted avg     0.6839    0.4925    0.4412       400\n",
      "\n",
      "15 0.040370172585965536 0.4925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6768    0.6569    0.6667       102\n",
      "         2.0     0.3488    0.9184    0.5056        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4925       400\n",
      "   macro avg     0.6811    0.4938    0.4406       400\n",
      "weighted avg     0.6827    0.4925    0.4414       400\n",
      "\n",
      "16 0.044306214575838825 0.4925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6667    0.6667    0.6667       102\n",
      "         2.0     0.3490    0.9082    0.5042        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4925       400\n",
      "   macro avg     0.6786    0.4937    0.4402       400\n",
      "weighted avg     0.6802    0.4925    0.4411       400\n",
      "\n",
      "17 0.04862601580065353 0.495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6509    0.6765    0.6635       102\n",
      "         2.0     0.3546    0.9082    0.5100        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4950       400\n",
      "   macro avg     0.6761    0.4962    0.4409       400\n",
      "weighted avg     0.6775    0.4950    0.4417       400\n",
      "\n",
      "18 0.0533669923120631 0.4975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6542    0.6863    0.6699       102\n",
      "         2.0     0.3560    0.9082    0.5115        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4975       400\n",
      "   macro avg     0.6772    0.4986    0.4429       400\n",
      "weighted avg     0.6787    0.4975    0.4436       400\n",
      "\n",
      "19 0.05857020818056667 0.4975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6514    0.6961    0.6730       102\n",
      "         2.0     0.3548    0.8980    0.5087        98\n",
      "         3.0     0.7500    0.0300    0.0577       100\n",
      "\n",
      "    accuracy                         0.4975       400\n",
      "   macro avg     0.6762    0.4985    0.4429       400\n",
      "weighted avg     0.6777    0.4975    0.4438       400\n",
      "\n",
      "20 0.06428073117284322 0.51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6893    0.6961    0.6927       102\n",
      "         2.0     0.3548    0.8980    0.5087        98\n",
      "         3.0     0.8000    0.0800    0.1455       100\n",
      "\n",
      "    accuracy                         0.5100       400\n",
      "   macro avg     0.6982    0.5110    0.4698       400\n",
      "weighted avg     0.6999    0.5100    0.4707       400\n",
      "\n",
      "21 0.07054802310718646 0.5125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6792    0.7059    0.6923       102\n",
      "         2.0     0.3592    0.8980    0.5131        98\n",
      "         3.0     0.8000    0.0800    0.1455       100\n",
      "\n",
      "    accuracy                         0.5125       400\n",
      "   macro avg     0.6968    0.5135    0.4708       400\n",
      "weighted avg     0.6984    0.5125    0.4717       400\n",
      "\n",
      "22 0.0774263682681127 0.5175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6852    0.7255    0.7048       102\n",
      "         2.0     0.3621    0.8980    0.5161        98\n",
      "         3.0     0.8000    0.0800    0.1455       100\n",
      "\n",
      "    accuracy                         0.5175       400\n",
      "   macro avg     0.6990    0.5184    0.4747       400\n",
      "weighted avg     0.7006    0.5175    0.4756       400\n",
      "\n",
      "23 0.08497534359086446 0.5175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6852    0.7255    0.7048       102\n",
      "         2.0     0.3621    0.8980    0.5161        98\n",
      "         3.0     0.8000    0.0800    0.1455       100\n",
      "\n",
      "    accuracy                         0.5175       400\n",
      "   macro avg     0.6990    0.5184    0.4747       400\n",
      "weighted avg     0.7006    0.5175    0.4756       400\n",
      "\n",
      "24 0.093260334688322 0.5175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6852    0.7255    0.7048       102\n",
      "         2.0     0.3621    0.8980    0.5161        98\n",
      "         3.0     0.8000    0.0800    0.1455       100\n",
      "\n",
      "    accuracy                         0.5175       400\n",
      "   macro avg     0.6990    0.5184    0.4747       400\n",
      "weighted avg     0.7006    0.5175    0.4756       400\n",
      "\n",
      "25 0.10235310218990264 0.5225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6881    0.7353    0.7109       102\n",
      "         2.0     0.3651    0.8980    0.5192        98\n",
      "         3.0     0.8182    0.0900    0.1622       100\n",
      "\n",
      "    accuracy                         0.5225       400\n",
      "   macro avg     0.7050    0.5233    0.4812       400\n",
      "weighted avg     0.7066    0.5225    0.4821       400\n",
      "\n",
      "26 0.11233240329780277 0.5225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6818    0.7353    0.7075       102\n",
      "         2.0     0.3667    0.8980    0.5207        98\n",
      "         3.0     0.8182    0.0900    0.1622       100\n",
      "\n",
      "    accuracy                         0.5225       400\n",
      "   macro avg     0.7038    0.5233    0.4807       400\n",
      "weighted avg     0.7054    0.5225    0.4816       400\n",
      "\n",
      "27 0.12328467394420665 0.5225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6786    0.7451    0.7103       102\n",
      "         2.0     0.3671    0.8878    0.5194        98\n",
      "         3.0     0.7500    0.0900    0.1607       100\n",
      "\n",
      "    accuracy                         0.5225       400\n",
      "   macro avg     0.6861    0.5232    0.4807       400\n",
      "weighted avg     0.6877    0.5225    0.4816       400\n",
      "\n",
      "28 0.13530477745798075 0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6786    0.7451    0.7103       102\n",
      "         2.0     0.3644    0.8776    0.5150        98\n",
      "         3.0     0.6923    0.0900    0.1593       100\n",
      "\n",
      "    accuracy                         0.5200       400\n",
      "   macro avg     0.6710    0.5207    0.4792       400\n",
      "weighted avg     0.6726    0.5200    0.4802       400\n",
      "\n",
      "29 0.1484968262254465 0.5175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6726    0.7451    0.7070       102\n",
      "         2.0     0.3617    0.8673    0.5105        98\n",
      "         3.0     0.6923    0.0900    0.1593       100\n",
      "\n",
      "    accuracy                         0.5175       400\n",
      "   macro avg     0.6688    0.5181    0.4773       400\n",
      "weighted avg     0.6704    0.5175    0.4783       400\n",
      "\n",
      "30 0.16297508346206444 0.5325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9487    0.3700    0.5324       100\n",
      "         1.0     0.6875    0.7549    0.7196       102\n",
      "         2.0     0.3668    0.8571    0.5138        98\n",
      "         3.0     0.7500    0.1500    0.2500       100\n",
      "\n",
      "    accuracy                         0.5325       400\n",
      "   macro avg     0.6883    0.5330    0.5039       400\n",
      "weighted avg     0.6899    0.5325    0.5050       400\n",
      "\n",
      "31 0.1788649529057435 0.5325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6875    0.7549    0.7196       102\n",
      "         2.0     0.3668    0.8571    0.5138        98\n",
      "         3.0     0.7619    0.1600    0.2645       100\n",
      "\n",
      "    accuracy                         0.5325       400\n",
      "   macro avg     0.6909    0.5330    0.5049       400\n",
      "weighted avg     0.6925    0.5325    0.5059       400\n",
      "\n",
      "32 0.19630406500402714 0.53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6814    0.7549    0.7163       102\n",
      "         2.0     0.3640    0.8469    0.5092        98\n",
      "         3.0     0.7619    0.1600    0.2645       100\n",
      "\n",
      "    accuracy                         0.5300       400\n",
      "   macro avg     0.6887    0.5305    0.5029       400\n",
      "weighted avg     0.6903    0.5300    0.5040       400\n",
      "\n",
      "33 0.21544346900318845 0.5325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6814    0.7549    0.7163       102\n",
      "         2.0     0.3661    0.8367    0.5093        98\n",
      "         3.0     0.7200    0.1800    0.2880       100\n",
      "\n",
      "    accuracy                         0.5325       400\n",
      "   macro avg     0.6787    0.5329    0.5088       400\n",
      "weighted avg     0.6803    0.5325    0.5099       400\n",
      "\n",
      "34 0.23644894126454083 0.53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6814    0.7549    0.7163       102\n",
      "         2.0     0.3620    0.8163    0.5016        98\n",
      "         3.0     0.6786    0.1900    0.2969       100\n",
      "\n",
      "    accuracy                         0.5300       400\n",
      "   macro avg     0.6673    0.5303    0.5091       400\n",
      "weighted avg     0.6689    0.5300    0.5102       400\n",
      "\n",
      "35 0.25950242113997374 0.535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6754    0.7549    0.7130       102\n",
      "         2.0     0.3657    0.8061    0.5032        98\n",
      "         3.0     0.6875    0.2200    0.3333       100\n",
      "\n",
      "    accuracy                         0.5350       400\n",
      "   macro avg     0.6690    0.5353    0.5178       400\n",
      "weighted avg     0.6706    0.5350    0.5189       400\n",
      "\n",
      "36 0.2848035868435802 0.5325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6754    0.7549    0.7130       102\n",
      "         2.0     0.3615    0.7857    0.4952        98\n",
      "         3.0     0.6571    0.2300    0.3407       100\n",
      "\n",
      "    accuracy                         0.5325       400\n",
      "   macro avg     0.6604    0.5327    0.5177       400\n",
      "weighted avg     0.6619    0.5325    0.5187       400\n",
      "\n",
      "37 0.3125715849688237 0.5325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6724    0.7647    0.7156       102\n",
      "         2.0     0.3619    0.7755    0.4935        98\n",
      "         3.0     0.6389    0.2300    0.3382       100\n",
      "\n",
      "    accuracy                         0.5325       400\n",
      "   macro avg     0.6551    0.5326    0.5173       400\n",
      "weighted avg     0.6567    0.5325    0.5184       400\n",
      "\n",
      "38 0.34304692863149194 0.545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6780    0.7843    0.7273       102\n",
      "         2.0     0.3668    0.7449    0.4916        98\n",
      "         3.0     0.6444    0.2900    0.4000       100\n",
      "\n",
      "    accuracy                         0.5450       400\n",
      "   macro avg     0.6592    0.5448    0.5351       400\n",
      "weighted avg     0.6607    0.5450    0.5363       400\n",
      "\n",
      "39 0.37649358067924693 0.5475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6780    0.7843    0.7273       102\n",
      "         2.0     0.3687    0.7449    0.4932        98\n",
      "         3.0     0.6522    0.3000    0.4110       100\n",
      "\n",
      "    accuracy                         0.5475       400\n",
      "   macro avg     0.6615    0.5473    0.5383       400\n",
      "weighted avg     0.6631    0.5475    0.5395       400\n",
      "\n",
      "40 0.41320124001153385 0.545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6780    0.7843    0.7273       102\n",
      "         2.0     0.3660    0.7245    0.4863        98\n",
      "         3.0     0.6200    0.3100    0.4133       100\n",
      "\n",
      "    accuracy                         0.5450       400\n",
      "   macro avg     0.6528    0.5447    0.5372       400\n",
      "weighted avg     0.6544    0.5450    0.5384       400\n",
      "\n",
      "41 0.4534878508128584 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9474    0.3600    0.5217       100\n",
      "         1.0     0.6723    0.7843    0.7240       102\n",
      "         2.0     0.3670    0.7041    0.4825        98\n",
      "         3.0     0.6364    0.3500    0.4516       100\n",
      "\n",
      "    accuracy                         0.5500       400\n",
      "   macro avg     0.6558    0.5496    0.5450       400\n",
      "weighted avg     0.6573    0.5500    0.5462       400\n",
      "\n",
      "42 0.49770235643321115 0.5575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9500    0.3800    0.5429       100\n",
      "         1.0     0.6723    0.7843    0.7240       102\n",
      "         2.0     0.3750    0.7041    0.4894        98\n",
      "         3.0     0.6316    0.3600    0.4586       100\n",
      "\n",
      "    accuracy                         0.5575       400\n",
      "   macro avg     0.6572    0.5571    0.5537       400\n",
      "weighted avg     0.6587    0.5575    0.5549       400\n",
      "\n",
      "43 0.5462277217684343 0.575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9500    0.3800    0.5429       100\n",
      "         1.0     0.6667    0.7843    0.7207       102\n",
      "         2.0     0.3920    0.7041    0.5036        98\n",
      "         3.0     0.6719    0.4300    0.5244       100\n",
      "\n",
      "    accuracy                         0.5750       400\n",
      "   macro avg     0.6701    0.5746    0.5729       400\n",
      "weighted avg     0.6715    0.5750    0.5740       400\n",
      "\n",
      "44 0.5994842503189411 0.5775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9500    0.3800    0.5429       100\n",
      "         1.0     0.6694    0.7941    0.7265       102\n",
      "         2.0     0.3882    0.6735    0.4925        98\n",
      "         3.0     0.6667    0.4600    0.5444       100\n",
      "\n",
      "    accuracy                         0.5775       400\n",
      "   macro avg     0.6686    0.5769    0.5766       400\n",
      "weighted avg     0.6700    0.5775    0.5777       400\n",
      "\n",
      "45 0.6579332246575682 0.585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9512    0.3900    0.5532       100\n",
      "         1.0     0.6750    0.7941    0.7297       102\n",
      "         2.0     0.3916    0.6633    0.4924        98\n",
      "         3.0     0.6712    0.4900    0.5665       100\n",
      "\n",
      "    accuracy                         0.5850       400\n",
      "   macro avg     0.6723    0.5843    0.5855       400\n",
      "weighted avg     0.6737    0.5850    0.5866       400\n",
      "\n",
      "46 0.7220809018385468 0.585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9512    0.3900    0.5532       100\n",
      "         1.0     0.6750    0.7941    0.7297       102\n",
      "         2.0     0.3916    0.6633    0.4924        98\n",
      "         3.0     0.6712    0.4900    0.5665       100\n",
      "\n",
      "    accuracy                         0.5850       400\n",
      "   macro avg     0.6723    0.5843    0.5855       400\n",
      "weighted avg     0.6737    0.5850    0.5866       400\n",
      "\n",
      "47 0.7924828983539177 0.5925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9524    0.4000    0.5634       100\n",
      "         1.0     0.6750    0.7941    0.7297       102\n",
      "         2.0     0.3988    0.6633    0.4981        98\n",
      "         3.0     0.6800    0.5100    0.5829       100\n",
      "\n",
      "    accuracy                         0.5925       400\n",
      "   macro avg     0.6765    0.5918    0.5935       400\n",
      "weighted avg     0.6779    0.5925    0.5947       400\n",
      "\n",
      "48 0.8697490026177834 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9149    0.4300    0.5850       100\n",
      "         1.0     0.6750    0.7941    0.7297       102\n",
      "         2.0     0.4076    0.6531    0.5020        98\n",
      "         3.0     0.6842    0.5200    0.5909       100\n",
      "\n",
      "    accuracy                         0.6000       400\n",
      "   macro avg     0.6704    0.5993    0.6019       400\n",
      "weighted avg     0.6718    0.6000    0.6030       400\n",
      "\n",
      "49 0.9545484566618342 0.5975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8776    0.4300    0.5772       100\n",
      "         1.0     0.6807    0.7941    0.7330       102\n",
      "         2.0     0.4040    0.6224    0.4900        98\n",
      "         3.0     0.6667    0.5400    0.5967       100\n",
      "\n",
      "    accuracy                         0.5975       400\n",
      "   macro avg     0.6572    0.5966    0.5992       400\n",
      "weighted avg     0.6586    0.5975    0.6004       400\n",
      "\n",
      "50 1.0476157527896652 0.6075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8519    0.4600    0.5974       100\n",
      "         1.0     0.6864    0.7941    0.7364       102\n",
      "         2.0     0.4126    0.6020    0.4896        98\n",
      "         3.0     0.6706    0.5700    0.6162       100\n",
      "\n",
      "    accuracy                         0.6075       400\n",
      "   macro avg     0.6554    0.6065    0.6099       400\n",
      "weighted avg     0.6567    0.6075    0.6111       400\n",
      "\n",
      "51 1.149756995397737 0.6175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8500    0.5100    0.6375       100\n",
      "         1.0     0.6991    0.7745    0.7349       102\n",
      "         2.0     0.4255    0.6122    0.5021        98\n",
      "         3.0     0.6628    0.5700    0.6129       100\n",
      "\n",
      "    accuracy                         0.6175       400\n",
      "   macro avg     0.6594    0.6167    0.6218       400\n",
      "weighted avg     0.6607    0.6175    0.6230       400\n",
      "\n",
      "52 1.261856883066021 0.6125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8154    0.5300    0.6424       100\n",
      "         1.0     0.7091    0.7647    0.7358       102\n",
      "         2.0     0.4234    0.5918    0.4936        98\n",
      "         3.0     0.6364    0.5600    0.5957       100\n",
      "\n",
      "    accuracy                         0.6125       400\n",
      "   macro avg     0.6460    0.6116    0.6169       400\n",
      "weighted avg     0.6475    0.6125    0.6181       400\n",
      "\n",
      "53 1.384886371393873 0.6225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8000    0.5600    0.6588       100\n",
      "         1.0     0.7264    0.7549    0.7404       102\n",
      "         2.0     0.4370    0.6020    0.5064        98\n",
      "         3.0     0.6404    0.5700    0.6032       100\n",
      "\n",
      "    accuracy                         0.6225       400\n",
      "   macro avg     0.6510    0.6217    0.6272       400\n",
      "weighted avg     0.6524    0.6225    0.6284       400\n",
      "\n",
      "54 1.5199110829529348 0.6275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7692    0.6000    0.6742       100\n",
      "         1.0     0.7451    0.7451    0.7451       102\n",
      "         2.0     0.4394    0.5918    0.5043        98\n",
      "         3.0     0.6477    0.5700    0.6064       100\n",
      "\n",
      "    accuracy                         0.6275       400\n",
      "   macro avg     0.6504    0.6267    0.6325       400\n",
      "weighted avg     0.6519    0.6275    0.6337       400\n",
      "\n",
      "55 1.6681005372000592 0.6275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7191    0.6400    0.6772       100\n",
      "         1.0     0.7604    0.7157    0.7374       102\n",
      "         2.0     0.4444    0.5714    0.5000        98\n",
      "         3.0     0.6517    0.5800    0.6138       100\n",
      "\n",
      "    accuracy                         0.6275       400\n",
      "   macro avg     0.6439    0.6268    0.6321       400\n",
      "weighted avg     0.6455    0.6275    0.6333       400\n",
      "\n",
      "56 1.8307382802953698 0.6225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7111    0.6400    0.6737       100\n",
      "         1.0     0.7604    0.7157    0.7374       102\n",
      "         2.0     0.4355    0.5510    0.4865        98\n",
      "         3.0     0.6444    0.5800    0.6105       100\n",
      "\n",
      "    accuracy                         0.6225       400\n",
      "   macro avg     0.6379    0.6217    0.6270       400\n",
      "weighted avg     0.6395    0.6225    0.6283       400\n",
      "\n",
      "57 2.0092330025650478 0.6175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6947    0.6600    0.6769       100\n",
      "         1.0     0.7717    0.6961    0.7320       102\n",
      "         2.0     0.4298    0.5306    0.4749        98\n",
      "         3.0     0.6304    0.5800    0.6042       100\n",
      "\n",
      "    accuracy                         0.6175       400\n",
      "   macro avg     0.6317    0.6167    0.6220       400\n",
      "weighted avg     0.6334    0.6175    0.6233       400\n",
      "\n",
      "58 2.2051307399030455 0.6175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7010    0.6800    0.6904       100\n",
      "         1.0     0.7640    0.6667    0.7120       102\n",
      "         2.0     0.4322    0.5204    0.4722        98\n",
      "         3.0     0.6250    0.6000    0.6122       100\n",
      "\n",
      "    accuracy                         0.6175       400\n",
      "   macro avg     0.6306    0.6168    0.6217       400\n",
      "weighted avg     0.6322    0.6175    0.6229       400\n",
      "\n",
      "59 2.4201282647943834 0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7000    0.7000    0.7000       100\n",
      "         1.0     0.7791    0.6569    0.7128       102\n",
      "         2.0     0.4444    0.5306    0.4837        98\n",
      "         3.0     0.6289    0.6100    0.6193       100\n",
      "\n",
      "    accuracy                         0.6250       400\n",
      "   macro avg     0.6381    0.6244    0.6289       400\n",
      "weighted avg     0.6398    0.6250    0.6301       400\n",
      "\n",
      "60 2.656087782946687 0.6275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6857    0.7200    0.7024       100\n",
      "         1.0     0.7738    0.6373    0.6989       102\n",
      "         2.0     0.4602    0.5306    0.4929        98\n",
      "         3.0     0.6327    0.6200    0.6263       100\n",
      "\n",
      "    accuracy                         0.6275       400\n",
      "   macro avg     0.6381    0.6270    0.6301       400\n",
      "weighted avg     0.6397    0.6275    0.6312       400\n",
      "\n",
      "61 2.9150530628251787 0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6636    0.7300    0.6952       100\n",
      "         1.0     0.7778    0.6176    0.6885       102\n",
      "         2.0     0.4602    0.5306    0.4929        98\n",
      "         3.0     0.6458    0.6200    0.6327       100\n",
      "\n",
      "    accuracy                         0.6250       400\n",
      "   macro avg     0.6369    0.6246    0.6273       400\n",
      "weighted avg     0.6384    0.6250    0.6283       400\n",
      "\n",
      "62 3.1992671377973845 0.615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6549    0.7400    0.6948       100\n",
      "         1.0     0.7625    0.5980    0.6703       102\n",
      "         2.0     0.4404    0.4898    0.4638        98\n",
      "         3.0     0.6429    0.6300    0.6364       100\n",
      "\n",
      "    accuracy                         0.6150       400\n",
      "   macro avg     0.6251    0.6145    0.6163       400\n",
      "weighted avg     0.6268    0.6150    0.6174       400\n",
      "\n",
      "63 3.5111917342151346 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6410    0.7500    0.6912       100\n",
      "         1.0     0.7532    0.5686    0.6480       102\n",
      "         2.0     0.4444    0.4898    0.4660        98\n",
      "         3.0     0.6429    0.6300    0.6364       100\n",
      "\n",
      "    accuracy                         0.6100       400\n",
      "   macro avg     0.6204    0.6096    0.6104       400\n",
      "weighted avg     0.6219    0.6100    0.6113       400\n",
      "\n",
      "64 3.8535285937105312 0.6175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6356    0.7500    0.6881       100\n",
      "         1.0     0.7500    0.5588    0.6404       102\n",
      "         2.0     0.4679    0.5204    0.4928        98\n",
      "         3.0     0.6598    0.6400    0.6497       100\n",
      "\n",
      "    accuracy                         0.6175       400\n",
      "   macro avg     0.6283    0.6173    0.6178       400\n",
      "weighted avg     0.6297    0.6175    0.6185       400\n",
      "\n",
      "65 4.229242874389499 0.6125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6333    0.7600    0.6909       100\n",
      "         1.0     0.7403    0.5588    0.6369       102\n",
      "         2.0     0.4630    0.5102    0.4854        98\n",
      "         3.0     0.6526    0.6200    0.6359       100\n",
      "\n",
      "    accuracy                         0.6125       400\n",
      "   macro avg     0.6223    0.6123    0.6123       400\n",
      "weighted avg     0.6237    0.6125    0.6130       400\n",
      "\n",
      "66 4.641588833612782 0.6175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6417    0.7700    0.7000       100\n",
      "         1.0     0.7368    0.5490    0.6292       102\n",
      "         2.0     0.4771    0.5306    0.5024        98\n",
      "         3.0     0.6526    0.6200    0.6359       100\n",
      "\n",
      "    accuracy                         0.6175       400\n",
      "   macro avg     0.6271    0.6174    0.6169       400\n",
      "weighted avg     0.6284    0.6175    0.6175       400\n",
      "\n",
      "67 5.09413801481638 0.6275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6583    0.7900    0.7182       100\n",
      "         1.0     0.7403    0.5588    0.6369       102\n",
      "         2.0     0.4818    0.5408    0.5096        98\n",
      "         3.0     0.6667    0.6200    0.6425       100\n",
      "\n",
      "    accuracy                         0.6275       400\n",
      "   macro avg     0.6368    0.6274    0.6268       400\n",
      "weighted avg     0.6381    0.6275    0.6274       400\n",
      "\n",
      "68 5.590810182512229 0.6225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6583    0.7900    0.7182       100\n",
      "         1.0     0.7308    0.5588    0.6333       102\n",
      "         2.0     0.4722    0.5204    0.4951        98\n",
      "         3.0     0.6596    0.6200    0.6392       100\n",
      "\n",
      "    accuracy                         0.6225       400\n",
      "   macro avg     0.6302    0.6223    0.6215       400\n",
      "weighted avg     0.6315    0.6225    0.6221       400\n",
      "\n",
      "69 6.135907273413176 0.615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6557    0.8000    0.7207       100\n",
      "         1.0     0.7368    0.5490    0.6292       102\n",
      "         2.0     0.4571    0.4898    0.4729        98\n",
      "         3.0     0.6392    0.6200    0.6294       100\n",
      "\n",
      "    accuracy                         0.6150       400\n",
      "   macro avg     0.6222    0.6147    0.6131       400\n",
      "weighted avg     0.6236    0.6150    0.6139       400\n",
      "\n",
      "70 6.7341506577508286 0.6075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6504    0.8000    0.7175       100\n",
      "         1.0     0.7179    0.5490    0.6222       102\n",
      "         2.0     0.4455    0.4592    0.4523        98\n",
      "         3.0     0.6327    0.6200    0.6263       100\n",
      "\n",
      "    accuracy                         0.6075       400\n",
      "   macro avg     0.6116    0.6071    0.6046       400\n",
      "weighted avg     0.6130    0.6075    0.6054       400\n",
      "\n",
      "71 7.390722033525782 0.6025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6371    0.7900    0.7054       100\n",
      "         1.0     0.7215    0.5588    0.6298       102\n",
      "         2.0     0.4343    0.4388    0.4365        98\n",
      "         3.0     0.6327    0.6200    0.6263       100\n",
      "\n",
      "    accuracy                         0.6025       400\n",
      "   macro avg     0.6064    0.6019    0.5995       400\n",
      "weighted avg     0.6078    0.6025    0.6005       400\n",
      "\n",
      "72 8.111308307896872 0.6125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6320    0.7900    0.7022       100\n",
      "         1.0     0.7308    0.5588    0.6333       102\n",
      "         2.0     0.4545    0.4592    0.4569        98\n",
      "         3.0     0.6531    0.6400    0.6465       100\n",
      "\n",
      "    accuracy                         0.6125       400\n",
      "   macro avg     0.6176    0.6120    0.6097       400\n",
      "weighted avg     0.6190    0.6125    0.6106       400\n",
      "\n",
      "73 8.902150854450392 0.615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6299    0.8000    0.7048       100\n",
      "         1.0     0.7308    0.5588    0.6333       102\n",
      "         2.0     0.4639    0.4592    0.4615        98\n",
      "         3.0     0.6531    0.6400    0.6465       100\n",
      "\n",
      "    accuracy                         0.6150       400\n",
      "   macro avg     0.6194    0.6145    0.6115       400\n",
      "weighted avg     0.6208    0.6150    0.6124       400\n",
      "\n",
      "74 9.770099572992256 0.615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6423    0.7900    0.7085       100\n",
      "         1.0     0.7215    0.5588    0.6298       102\n",
      "         2.0     0.4639    0.4592    0.4615        98\n",
      "         3.0     0.6436    0.6500    0.6468       100\n",
      "\n",
      "    accuracy                         0.6150       400\n",
      "   macro avg     0.6178    0.6145    0.6117       400\n",
      "weighted avg     0.6191    0.6150    0.6125       400\n",
      "\n",
      "75 10.722672220103243 0.6075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6220    0.7900    0.6960       100\n",
      "         1.0     0.7105    0.5294    0.6067       102\n",
      "         2.0     0.4688    0.4592    0.4639        98\n",
      "         3.0     0.6436    0.6500    0.6468       100\n",
      "\n",
      "    accuracy                         0.6075       400\n",
      "   macro avg     0.6112    0.6071    0.6034       400\n",
      "weighted avg     0.6124    0.6075    0.6041       400\n",
      "\n",
      "76 11.768119524349991 0.605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6190    0.7800    0.6903       100\n",
      "         1.0     0.7105    0.5294    0.6067       102\n",
      "         2.0     0.4639    0.4592    0.4615        98\n",
      "         3.0     0.6436    0.6500    0.6468       100\n",
      "\n",
      "    accuracy                         0.6050       400\n",
      "   macro avg     0.6093    0.6046    0.6013       400\n",
      "weighted avg     0.6105    0.6050    0.6021       400\n",
      "\n",
      "77 12.91549665014884 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6172    0.7900    0.6930       100\n",
      "         1.0     0.7027    0.5098    0.5909       102\n",
      "         2.0     0.4545    0.4592    0.4569        98\n",
      "         3.0     0.6465    0.6400    0.6432       100\n",
      "\n",
      "    accuracy                         0.6000       400\n",
      "   macro avg     0.6052    0.5997    0.5960       400\n",
      "weighted avg     0.6065    0.6000    0.5967       400\n",
      "\n",
      "78 14.174741629268063 0.605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6202    0.8000    0.6987       100\n",
      "         1.0     0.7162    0.5196    0.6023       102\n",
      "         2.0     0.4592    0.4592    0.4592        98\n",
      "         3.0     0.6465    0.6400    0.6432       100\n",
      "\n",
      "    accuracy                         0.6050       400\n",
      "   macro avg     0.6105    0.6047    0.6008       400\n",
      "weighted avg     0.6118    0.6050    0.6016       400\n",
      "\n",
      "79 15.556761439304722 0.5925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6016    0.7700    0.6754       100\n",
      "         1.0     0.6933    0.5098    0.5876       102\n",
      "         2.0     0.4490    0.4490    0.4490        98\n",
      "         3.0     0.6465    0.6400    0.6432       100\n",
      "\n",
      "    accuracy                         0.5925       400\n",
      "   macro avg     0.5976    0.5922    0.5888       400\n",
      "weighted avg     0.5988    0.5925    0.5895       400\n",
      "\n",
      "80 17.07352647470692 0.5925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6080    0.7600    0.6756       100\n",
      "         1.0     0.6883    0.5196    0.5922       102\n",
      "         2.0     0.4444    0.4490    0.4467        98\n",
      "         3.0     0.6465    0.6400    0.6432       100\n",
      "\n",
      "    accuracy                         0.5925       400\n",
      "   macro avg     0.5968    0.5921    0.5894       400\n",
      "weighted avg     0.5980    0.5925    0.5901       400\n",
      "\n",
      "81 18.73817422860385 0.595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6080    0.7600    0.6756       100\n",
      "         1.0     0.6750    0.5294    0.5934       102\n",
      "         2.0     0.4583    0.4490    0.4536        98\n",
      "         3.0     0.6465    0.6400    0.6432       100\n",
      "\n",
      "    accuracy                         0.5950       400\n",
      "   macro avg     0.5969    0.5946    0.5914       400\n",
      "weighted avg     0.5980    0.5950    0.5921       400\n",
      "\n",
      "82 20.565123083486537 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6179    0.7600    0.6816       100\n",
      "         1.0     0.6750    0.5294    0.5934       102\n",
      "         2.0     0.4694    0.4694    0.4694        98\n",
      "         3.0     0.6465    0.6400    0.6432       100\n",
      "\n",
      "    accuracy                         0.6000       400\n",
      "   macro avg     0.6022    0.5997    0.5969       400\n",
      "weighted avg     0.6032    0.6000    0.5975       400\n",
      "\n",
      "83 22.570197196339215 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6179    0.7600    0.6816       100\n",
      "         1.0     0.6750    0.5294    0.5934       102\n",
      "         2.0     0.4694    0.4694    0.4694        98\n",
      "         3.0     0.6465    0.6400    0.6432       100\n",
      "\n",
      "    accuracy                         0.6000       400\n",
      "   macro avg     0.6022    0.5997    0.5969       400\n",
      "weighted avg     0.6032    0.6000    0.5975       400\n",
      "\n",
      "84 24.770763559917114 0.5975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6148    0.7500    0.6757       100\n",
      "         1.0     0.6667    0.5294    0.5902       102\n",
      "         2.0     0.4694    0.4694    0.4694        98\n",
      "         3.0     0.6465    0.6400    0.6432       100\n",
      "\n",
      "    accuracy                         0.5975       400\n",
      "   macro avg     0.5993    0.5972    0.5946       400\n",
      "weighted avg     0.6003    0.5975    0.5952       400\n",
      "\n",
      "85 27.185882427329428 0.5925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6066    0.7400    0.6667       100\n",
      "         1.0     0.6667    0.5294    0.5902       102\n",
      "         2.0     0.4639    0.4592    0.4615        98\n",
      "         3.0     0.6400    0.6400    0.6400       100\n",
      "\n",
      "    accuracy                         0.5925       400\n",
      "   macro avg     0.5943    0.5921    0.5896       400\n",
      "weighted avg     0.5953    0.5925    0.5902       400\n",
      "\n",
      "86 29.836472402833405 0.5975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6148    0.7500    0.6757       100\n",
      "         1.0     0.6790    0.5392    0.6011       102\n",
      "         2.0     0.4646    0.4694    0.4670        98\n",
      "         3.0     0.6429    0.6300    0.6364       100\n",
      "\n",
      "    accuracy                         0.5975       400\n",
      "   macro avg     0.6003    0.5972    0.5950       400\n",
      "weighted avg     0.6014    0.5975    0.5957       400\n",
      "\n",
      "87 32.745491628777316 0.595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6098    0.7500    0.6726       100\n",
      "         1.0     0.6790    0.5392    0.6011       102\n",
      "         2.0     0.4646    0.4694    0.4670        98\n",
      "         3.0     0.6392    0.6200    0.6294       100\n",
      "\n",
      "    accuracy                         0.5950       400\n",
      "   macro avg     0.5981    0.5947    0.5925       400\n",
      "weighted avg     0.5992    0.5950    0.5932       400\n",
      "\n",
      "88 35.938136638046295 0.595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6179    0.7600    0.6816       100\n",
      "         1.0     0.6835    0.5294    0.5967       102\n",
      "         2.0     0.4554    0.4694    0.4623        98\n",
      "         3.0     0.6392    0.6200    0.6294       100\n",
      "\n",
      "    accuracy                         0.5950       400\n",
      "   macro avg     0.5990    0.5947    0.5925       400\n",
      "weighted avg     0.6002    0.5950    0.5932       400\n",
      "\n",
      "89 39.4420605943766 0.5925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5984    0.7600    0.6696       100\n",
      "         1.0     0.6842    0.5098    0.5843       102\n",
      "         2.0     0.4653    0.4796    0.4724        98\n",
      "         3.0     0.6458    0.6200    0.6327       100\n",
      "\n",
      "    accuracy                         0.5925       400\n",
      "   macro avg     0.5985    0.5923    0.5897       400\n",
      "weighted avg     0.5995    0.5925    0.5903       400\n",
      "\n",
      "90 43.287612810830616 0.5875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5846    0.7600    0.6609       100\n",
      "         1.0     0.6800    0.5000    0.5763       102\n",
      "         2.0     0.4700    0.4796    0.4747        98\n",
      "         3.0     0.6421    0.6100    0.6256       100\n",
      "\n",
      "    accuracy                         0.5875       400\n",
      "   macro avg     0.5942    0.5874    0.5844       400\n",
      "weighted avg     0.5952    0.5875    0.5849       400\n",
      "\n",
      "91 47.50810162102798 0.585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5630    0.7600    0.6468       100\n",
      "         1.0     0.6933    0.5098    0.5876       102\n",
      "         2.0     0.4688    0.4592    0.4639        98\n",
      "         3.0     0.6489    0.6100    0.6289       100\n",
      "\n",
      "    accuracy                         0.5850       400\n",
      "   macro avg     0.5935    0.5847    0.5818       400\n",
      "weighted avg     0.5946    0.5850    0.5824       400\n",
      "\n",
      "92 52.140082879996896 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5547    0.7600    0.6414       100\n",
      "         1.0     0.6892    0.5000    0.5795       102\n",
      "         2.0     0.4688    0.4592    0.4639        98\n",
      "         3.0     0.6452    0.6000    0.6218       100\n",
      "\n",
      "    accuracy                         0.5800       400\n",
      "   macro avg     0.5895    0.5798    0.5766       400\n",
      "weighted avg     0.5906    0.5800    0.5772       400\n",
      "\n",
      "93 57.223676593502205 0.5775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5429    0.7600    0.6333       100\n",
      "         1.0     0.6849    0.4902    0.5714       102\n",
      "         2.0     0.4737    0.4592    0.4663        98\n",
      "         3.0     0.6522    0.6000    0.6250       100\n",
      "\n",
      "    accuracy                         0.5775       400\n",
      "   macro avg     0.5884    0.5773    0.5740       400\n",
      "weighted avg     0.5895    0.5775    0.5745       400\n",
      "\n",
      "94 62.802914418342596 0.5625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5205    0.7600    0.6179       100\n",
      "         1.0     0.6714    0.4608    0.5465       102\n",
      "         2.0     0.4731    0.4490    0.4607        98\n",
      "         3.0     0.6374    0.5800    0.6073       100\n",
      "\n",
      "    accuracy                         0.5625       400\n",
      "   macro avg     0.5756    0.5624    0.5581       400\n",
      "weighted avg     0.5766    0.5625    0.5585       400\n",
      "\n",
      "95 68.92612104349702 0.5475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5067    0.7600    0.6080       100\n",
      "         1.0     0.6567    0.4314    0.5207       102\n",
      "         2.0     0.4574    0.4388    0.4479        98\n",
      "         3.0     0.6292    0.5600    0.5926       100\n",
      "\n",
      "    accuracy                         0.5475       400\n",
      "   macro avg     0.5625    0.5475    0.5423       400\n",
      "weighted avg     0.5635    0.5475    0.5427       400\n",
      "\n",
      "96 75.64633275546291 0.5425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4841    0.7600    0.5914       100\n",
      "         1.0     0.6515    0.4216    0.5119       102\n",
      "         2.0     0.4719    0.4286    0.4492        98\n",
      "         3.0     0.6364    0.5600    0.5957       100\n",
      "\n",
      "    accuracy                         0.5425       400\n",
      "   macro avg     0.5610    0.5425    0.5371       400\n",
      "weighted avg     0.5619    0.5425    0.5374       400\n",
      "\n",
      "97 83.02175681319753 0.5275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4578    0.7600    0.5714       100\n",
      "         1.0     0.6508    0.4020    0.4970       102\n",
      "         2.0     0.4828    0.4286    0.4541        98\n",
      "         3.0     0.6190    0.5200    0.5652       100\n",
      "\n",
      "    accuracy                         0.5275       400\n",
      "   macro avg     0.5526    0.5276    0.5219       400\n",
      "weighted avg     0.5534    0.5275    0.5221       400\n",
      "\n",
      "98 91.11627561154896 0.51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4318    0.7600    0.5507       100\n",
      "         1.0     0.6610    0.3824    0.4845       102\n",
      "         2.0     0.4699    0.3980    0.4309        98\n",
      "         3.0     0.6098    0.5000    0.5495       100\n",
      "\n",
      "    accuracy                         0.5100       400\n",
      "   macro avg     0.5431    0.5101    0.5039       400\n",
      "weighted avg     0.5441    0.5100    0.5042       400\n",
      "\n",
      "99 100.0 0.495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4074    0.7700    0.5329       100\n",
      "         1.0     0.6667    0.3725    0.4780       102\n",
      "         2.0     0.4675    0.3673    0.4114        98\n",
      "         3.0     0.6104    0.4700    0.5311       100\n",
      "\n",
      "    accuracy                         0.4950       400\n",
      "   macro avg     0.5380    0.4950    0.4883       400\n",
      "weighted avg     0.5390    0.4950    0.4887       400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6446    0.7800    0.7059       100\n",
      "         1.0     0.7368    0.5490    0.6292       102\n",
      "         2.0     0.4862    0.5408    0.5121        98\n",
      "         3.0     0.6596    0.6200    0.6392       100\n",
      "\n",
      "    accuracy                         0.6225       400\n",
      "   macro avg     0.6318    0.6225    0.6216       400\n",
      "weighted avg     0.6331    0.6225    0.6222       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# åç«¯ç½‘ç»œLPAåˆ†ç±»\n",
    "import numpy as np\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "X = features  # è¾“å…¥\n",
    "y = label  # è¾“å‡º\n",
    "rng = np.random.RandomState(9)  # éšæœºæ•°ç§å­\n",
    "indices = np.arange(len(y))\n",
    "rng.shuffle(indices)  # å°†ç´¢å¼•æ‰“ä¹±\n",
    "# print(X[0])\n",
    "\n",
    "n_total_samples = len(y)\n",
    "# n_labeled_points = 2795  # å·²æ ‡è®°/æ ·æœ¬æ•°\n",
    "n_labeled_points = 1600  # å·²æ ‡è®°æ ·æœ¬æ•°1260 1440\n",
    "\n",
    "unlabeled_set = indices[n_labeled_points:]\n",
    "\n",
    "y_train = np.copy(y)\n",
    "y_train[unlabeled_set] = -1  # æœªæ ‡è®°æ ·æœ¬é›†yè®¾ä¸º-1\n",
    "\n",
    "num=100\n",
    "accuracy = []\n",
    "gammas = np.logspace(-2, 2, num=num)\n",
    "# gammas = range(100)\n",
    "score_in = 0\n",
    "for i in range(num):\n",
    "    lp_model = LabelSpreading(gamma=gammas[i], max_iter=30, kernel='rbf')\n",
    "    lp_model.fit(X, y_train)\n",
    "    predicted_labels = lp_model.transduction_[unlabeled_set]\n",
    "    true_labels = y[unlabeled_set]\n",
    "    score = accuracy_score(true_labels, predicted_labels)\n",
    "    # if score > score_in:\n",
    "    #     gamma_fin = gammas[i]\n",
    "    accuracy.append(score)\n",
    "    print(i,gammas[i],score)\n",
    "    print(classification_report(true_labels, predicted_labels, digits=4))\n",
    "\n",
    "# lp_model = LabelSpreading(gamma=0.24, max_iter=200, kernel='rbf')# bert2000\n",
    "lp_model = LabelSpreading(gamma=4.75, max_iter=200, kernel='rbf')# tf-idf2000\n",
    "# lp_model = LabelSpreading(kernel='knn', n_neighbors=9, max_iter=100)\n",
    "lp_model.fit(X, y_train)\n",
    "predicted_labels = lp_model.transduction_[unlabeled_set]\n",
    "true_labels = y[unlabeled_set]\n",
    "print(classification_report(true_labels, predicted_labels, digits=4))\n",
    "\n",
    "\n",
    "\n",
    "# print(\n",
    "#     \"Label Spreading model: %d labeled & %d unlabeled points (%d total)\"\n",
    "#     % (n_labeled_points, n_total_samples - n_labeled_points, n_total_samples)\n",
    "# )\n",
    "# print(classification_report(true_labels, predicted_labels))\n",
    "# print(true_labels)\n",
    "# print(predicted_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6348    0.7374    0.6822        99\n",
      "         1.0     0.7576    0.6637    0.7075       113\n",
      "         2.0     0.5146    0.5300    0.5222       100\n",
      "         3.0     0.6506    0.6136    0.6316        88\n",
      "\n",
      "    accuracy                         0.6375       400\n",
      "   macro avg     0.6394    0.6362    0.6359       400\n",
      "weighted avg     0.6429    0.6375    0.6382       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lp_model = LabelSpreading(gamma=7.4, max_iter=200, kernel='rbf')# tf-idf2000\n",
    "# lp_model = LabelSpreading(kernel='knn', n_neighbors=9, max_iter=100)\n",
    "lp_model.fit(X, y_train)\n",
    "predicted_labels = lp_model.transduction_[unlabeled_set]\n",
    "true_labels = y[unlabeled_set]\n",
    "print(classification_report(true_labels, predicted_labels, digits=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6486    0.7200    0.6825       100\n",
      "         1.0     0.7412    0.6176    0.6738       102\n",
      "         2.0     0.4318    0.3878    0.4086        98\n",
      "         3.0     0.5862    0.6800    0.6296       100\n",
      "\n",
      "    accuracy                         0.6025       400\n",
      "   macro avg     0.6020    0.6014    0.5986       400\n",
      "weighted avg     0.6035    0.6025    0.5999       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RF\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = features  # è¾“å…¥\n",
    "y = label  # è¾“å‡º\n",
    "\n",
    "rng = np.random.RandomState(9)  # éšæœºæ•°ç§å­\n",
    "indices = np.arange(len(y))\n",
    "rng.shuffle(indices)  # å°†ç´¢å¼•æ‰“ä¹±\n",
    "# print(X[0])\n",
    "\n",
    "n_total_samples = len(y)\n",
    "n_labeled_points = 1600  # å·²æ ‡è®°æ ·æœ¬æ•°\n",
    "\n",
    "unlabeled_set = indices[n_labeled_points:]\n",
    "labeled_set = indices[:n_labeled_points]\n",
    "X_train = X[labeled_set]\n",
    "y_train = y[labeled_set]\n",
    "X_test = X[unlabeled_set]\n",
    "y_true = y[unlabeled_set]\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=20)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print(classification_report(y_true, y_predict, digits=4))\n",
    "\n",
    "# # è®¾ç½®å¼±å­¦ä¹ å™¨æ•°é‡ä¸º10\n",
    "# for i in range(1,100):\n",
    "#     model = RandomForestClassifier(n_estimators=i)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_predict = model.predict(X_test)\n",
    "#     print(i, accuracy_score(y_true, y_predict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6854    0.6162    0.6489        99\n",
      "         1.0     0.6522    0.7965    0.7171       113\n",
      "         2.0     0.5000    0.4600    0.4792       100\n",
      "         3.0     0.6543    0.6023    0.6272        88\n",
      "\n",
      "    accuracy                         0.6250       400\n",
      "   macro avg     0.6230    0.6187    0.6181       400\n",
      "weighted avg     0.6228    0.6250    0.6210       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=39)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print(classification_report(y_true, y_predict, digits=4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}